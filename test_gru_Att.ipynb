{"cells":[{"cell_type":"code","execution_count":1,"id":"e8vkfZSUsZ9b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2279,"status":"ok","timestamp":1649419426232,"user":{"displayName":"Вика","userId":"07891139911062556455"},"user_tz":-180},"id":"e8vkfZSUsZ9b","outputId":"0a4a2b6b-fc50-4ac0-87ee-295d98324a86"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"id":"gzBhWOnUDOXL","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7302,"status":"ok","timestamp":1649419433525,"user":{"displayName":"Вика","userId":"07891139911062556455"},"user_tz":-180},"id":"gzBhWOnUDOXL","outputId":"7b78b79a-5965-4d7b-d8cc-6f7c8cad7dcd","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: youtokentome in /usr/local/lib/python3.7/dist-packages (1.0.6)\n","Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from youtokentome) (7.1.2)\n"]}],"source":["!pip install youtokentome"]},{"cell_type":"code","execution_count":3,"id":"ab9ca873","metadata":{"id":"ab9ca873","executionInfo":{"status":"ok","timestamp":1649419440417,"user_tz":-180,"elapsed":6901,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","\n","import youtokentome as yttm\n","import numpy as np\n","\n","import random\n","import math\n","import time\n","import pickle\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":4,"id":"b6018908","metadata":{"id":"b6018908","executionInfo":{"status":"ok","timestamp":1649419440419,"user_tz":-180,"elapsed":18,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":5,"id":"f92d980d","metadata":{"id":"f92d980d","executionInfo":{"status":"ok","timestamp":1649419441020,"user_tz":-180,"elapsed":617,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# device = torch.device('cpu')"]},{"cell_type":"code","execution_count":6,"id":"3089450a","metadata":{"id":"3089450a","executionInfo":{"status":"ok","timestamp":1649419441021,"user_tz":-180,"elapsed":12,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["# token_model = yttm.BPE(model='try_poems_embed_yttm.model', n_threads=-1)\n","token_model = yttm.BPE(model='/content/drive/MyDrive/Colab Notebooks/NLP_poems/voc10k_poems_embed_yttm.model', n_threads=-1)"]},{"cell_type":"code","execution_count":7,"id":"ca3d5413","metadata":{"id":"ca3d5413","executionInfo":{"status":"ok","timestamp":1649419441022,"user_tz":-180,"elapsed":12,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["class newDataset(Dataset):\n","    def __init__(self, data_list_of_list):\n","        self.data = data_list_of_list\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        return self.data[index]\n","\n","    def cut_length(self):\n","#         middle_len = sum([len(text) for text in self.data])/len(self.data)\n","#         limit = int(middle_len)*2\n","        limit = 10\n","        self.data = [text if len(text)<limit else text[:limit] for text in self.data]\n","\n","    def distribute_data(self, share_tr, share_val):  # examle = (0.8, 0.1)\n","        rand_i = np.random.permutation(len(self.data))\n","        n1 = int(len(self.data) * share_tr)\n","        n2 = int(len(self.data) * share_val)\n","        # return self.data[rand_i[0: n1]], self.data[rand_i[n1: n1 + n2]], self.data[rand_i[n1 + n2:]]\n","        return [self.data[i] for i in rand_i[0: n1]], \\\n","               [self.data[i] for i in rand_i[n1: n1 + n2]], \\\n","               [self.data[i] for i in rand_i[n1 + n2:]]\n","    \n","def padding(batch):\n","    pad_id = token_model.subword_to_id('<PAD>')\n","    \n","    batch = [torch.tensor(x) for x in batch]\n","    batch = pad_sequence(batch, batch_first=False, padding_value=pad_id)  # batch_first=True -> [batch size, len]\n","    return batch\n","    # return batch.to(device)"]},{"cell_type":"code","execution_count":8,"id":"04f0c0b2","metadata":{"id":"04f0c0b2","executionInfo":{"status":"ok","timestamp":1649419441022,"user_tz":-180,"elapsed":11,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        \n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        \n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        \n","        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers) # dropout = dropout\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src):      \n","        #src = [src len, batch size]\n","        \n","        embedded = self.dropout(self.embedding(src))\n","        #embedded = [src len, batch size, emb dim]\n","        \n","        outputs, hidden = self.rnn(embedded)\n","        #outputs = [src len, batch size, hid dim]\n","        #hidden = [n layers, batch size, hid dim]\n","        \n","        #outputs are always from the top hidden layer\n","        #hidden - it will be first hid states in decoder\n","        return outputs, hidden"]},{"cell_type":"code","source":["class Attention(nn.Module):\n","    def __init__(self, hid_dim):\n","        super().__init__()\n","        \n","        self.attn = nn.Linear(hid_dim * 2, hid_dim)\n","        self.v = nn.Linear(hid_dim, 1, bias = False)\n","        \n","    def forward(self, hidden, encoder_outputs):\n","        \n","        #hidden = [batch size, hid dim]\n","        #encoder_outputs = [src len, batch size, hid dim]\n","        \n","        batch_size = encoder_outputs.shape[1]\n","        src_len = encoder_outputs.shape[0]\n","        \n","        #repeat decoder hidden state src_len times\n","        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        \n","        #hidden = [batch size, src len, hid dim]\n","        #encoder_outputs = [batch size, src len, hid dim]\n","        \n","        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n","        #energy = [batch size, src len, hid dim]\n","\n","        attention = self.v(energy).squeeze(2)\n","        #attention= [batch size, src len]\n","        \n","        return F.softmax(attention, dim=1)"],"metadata":{"id":"N7n7rHfqF90n","executionInfo":{"status":"ok","timestamp":1649419441023,"user_tz":-180,"elapsed":11,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"id":"N7n7rHfqF90n","execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":10,"id":"e524e3a2","metadata":{"id":"e524e3a2","executionInfo":{"status":"ok","timestamp":1649419441024,"user_tz":-180,"elapsed":12,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout, attention):\n","        super().__init__()\n","        \n","        self.output_dim = output_dim  # the size of the vocabulary for the output/target.\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","\n","        self.attention = attention\n","        \n","        self.embedding = nn.Embedding(output_dim, emb_dim) # 1 - size of dict emb, 2 - size of emb vec\n","        \n","        self.rnn = nn.GRU(hid_dim + emb_dim, hid_dim, n_layers) # dropout = dropout\n","        \n","        self.fc_out = nn.Linear(hid_dim * 2 + emb_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden, encoder_outputs):\n","\n","        #input = [batch size]\n","        #hidden = [n layers, batch size, hid dim]\n","        #encoder_outputs = [src len, batch size, hid dim]\n","        \n","        input = input.unsqueeze(0) \n","        #input = [1, batch size]\n","        embedded = self.dropout(self.embedding(input))\n","        #embedded = [1, batch size, emb dim]\n","                \n","        last_hidden = hidden[-1]\n","        #hidden = [batch size, hid dim]        \n","        a = self.attention(last_hidden, encoder_outputs)    \n","        #a = [batch size, src len]\n","        a = a.unsqueeze(1)\n","        #a = [batch size, 1, src len]\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        #encoder_outputs = [batch size, src len, hid dim]\n","        \n","        weighted = torch.bmm(a, encoder_outputs)    \n","        #weighted = [batch size, 1, hid dim]\n","        weighted = weighted.permute(1, 0, 2)\n","        #weighted = [1, batch size, enc hid dim]\n","        \n","        rnn_input = torch.cat((embedded, weighted), dim = 2)\n","        #rnn_input = [1, batch size, hid dim + emb dim]\n","        \n","        output, hidden = self.rnn(rnn_input, hidden)\n","        #output = [1, batch size, hid dim], seq len will always be 1 in the decoder\n","        #hidden = [n layers, batch size, hid dim]\n","        \n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted = weighted.squeeze(0)\n","        \n","        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n","        #prediction = [batch size, output dim]\n","        \n","        return prediction, hidden"]},{"cell_type":"code","execution_count":11,"id":"c49c37e0","metadata":{"id":"c49c37e0","executionInfo":{"status":"ok","timestamp":1649419441025,"user_tz":-180,"elapsed":12,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","    def forward(self, src, trg, teacher_forcing_ratio = 0.2):\n","        \n","        #src = [src len, batch size]\n","        #trg = [trg len, batch size]\n","        #teacher_forcing_ratio=0.75 -> use ground-truth inputs 75% of the time\n","        \n","        batch_size = trg.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","        \n","        #encoder_outputs is all hidden states of the input sequence\n","        #hidden is the final hidden states, passed through a linear layer\n","        encoder_outputs, hidden = self.encoder(src)\n","        \n","        #first input to the decoder is the <bos> tokens\n","        input = trg[0,:]  \n","        \n","        for t in range(1, trg_len):\n","            \n","            #insert input token emb-g, previous hidden state and all encoder hidden states\n","            #receive output tensor (predictions) and new hidden state\n","            output, hidden = self.decoder(input, hidden, encoder_outputs)\n","            \n","            outputs[t] = output\n","            \n","            teacher_force = random.random() < teacher_forcing_ratio\n","            \n","            #get the highest predicted token\n","            top1 = output.argmax(1) \n","            \n","            #if teacher forcing, use actual next token, else use predicted token\n","            input = trg[t] if teacher_force else top1\n","        \n","        return outputs"]},{"cell_type":"code","execution_count":12,"id":"6c03553f","metadata":{"id":"6c03553f","executionInfo":{"status":"ok","timestamp":1649419441451,"user_tz":-180,"elapsed":437,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["INPUT_DIM = token_model.vocab_size() \n","OUTPUT_DIM = INPUT_DIM\n","ENC_EMB_DIM = 128 #128\n","DEC_EMB_DIM = 128 #128\n","HID_DIM = 256 #256\n","N_LAYERS = 2 \n","ENC_DROPOUT = 0.2\n","DEC_DROPOUT = 0.2\n","\n","attn = Attention(HID_DIM)\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT, attn)\n","\n","model = Seq2Seq(enc, dec, device).to(device)"]},{"cell_type":"code","execution_count":13,"id":"a28baf9d","metadata":{"id":"a28baf9d","executionInfo":{"status":"ok","timestamp":1649419441452,"user_tz":-180,"elapsed":11,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["PAD_ID = token_model.subword_to_id('<PAD>')\n","criterion = nn.CrossEntropyLoss(ignore_index = PAD_ID)"]},{"cell_type":"code","execution_count":14,"id":"IJQffBFbO4kw","metadata":{"id":"IJQffBFbO4kw","executionInfo":{"status":"ok","timestamp":1649419441454,"user_tz":-180,"elapsed":12,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["def test(model, loader, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    outputs_list = []\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(tqdm(loader)):\n","            batch = batch.to(device, non_blocking=True)\n","            src = batch\n","            trg = batch\n","\n","            output = model(src, trg, 0) #turn off teacher forcing\n","            outputs_list.append(torch.transpose(output, 0, 1))\n","\n","            #trg = [trg len, batch size]\n","            #output = [trg len, batch size, output dim]\n","\n","            output_dim = output.shape[-1]\n","\n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            #trg = [(trg len - 1) * batch size]\n","            #output = [(trg len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, trg)\n","            \n","            epoch_loss += loss.item()\n","      \n","    return epoch_loss / len(loader), outputs_list"]},{"cell_type":"code","source":["# optimizer.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/NLP_poems/b7e10dr03_optim.pt'))\n","# print(optimizer.param_groups[0]['lr'])\n","# print(optimizer.param_groups[0]['initial_lr'])\n","# print(optimizer.param_groups)"],"metadata":{"id":"NdaSGo5KZgDN","executionInfo":{"status":"ok","timestamp":1649419441455,"user_tz":-180,"elapsed":12,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"id":"NdaSGo5KZgDN","execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"id":"4v_oHkIGWHGB","metadata":{"id":"4v_oHkIGWHGB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649419445401,"user_tz":-180,"elapsed":10,"user":{"displayName":"Вика","userId":"07891139911062556455"}},"outputId":"1440052c-421d-4816-ce6e-2910429ea0fc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":16}],"source":["# checkpoint = torch.load('trylr005_17k_checkpoint.pt')\n","checkpoint = torch.load('/content/drive/MyDrive/Colab Notebooks/NLP_poems/AdamW_one_C005_same_drEm2_voc10k_tf2_20406080len100_Att_checkp_best.pt', \n","                        map_location=torch.device('cpu'))\n","model.load_state_dict(checkpoint['model_state_dict'])"]},{"cell_type":"code","execution_count":17,"id":"6d0b297f","metadata":{"id":"6d0b297f","executionInfo":{"status":"ok","timestamp":1649419454381,"user_tz":-180,"elapsed":402,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["# with open('data/try_test_data_token.pickle', 'rb', ) as file:\n","with open('/content/drive/MyDrive/Colab Notebooks/NLP_poems/data/voc10klen100_test_data_token.pickle', 'rb', ) as file:\n","    test_data_token = pickle.load(file)\n","test_loader_load = DataLoader(\n","    test_data_token, batch_size=32, shuffle=False, num_workers=1, pin_memory=True, collate_fn=padding)"]},{"cell_type":"code","execution_count":18,"id":"6c4fe1ca","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["472ff8a1e7d2494b85c3f34a0f0e7c16","9e2b495c2b584f559f10f2acd5764d95","e6edf34e2b6b4ab4b5709c1709c5963b","8fd9fd2e8d2843ec8e631e170a86a5bb","b31f437ade0a494a89f356b4cf03b7cd","550442da8825482ea3634146c41bbe96","9b3d2b0f7e48469d9b808b1d35ec5955","dd7acc15e6174849825aa184db3873ad","7b41ab5faafe4909a06db0c8f4d7a9bf","54ec14605477492fa01f771565402aef","19dacdf2a08c446bb4473d32f4522e7b"]},"executionInfo":{"elapsed":200970,"status":"ok","timestamp":1649419658592,"user":{"displayName":"Вика","userId":"07891139911062556455"},"user_tz":-180},"id":"6c4fe1ca","outputId":"c3941835-a432-49e2-fe5f-22ae6d5f6e99"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/56 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"472ff8a1e7d2494b85c3f34a0f0e7c16"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["| Test Loss: 0.705 | Test PPL:   2.025 |\n"]}],"source":["test_loss, test_poems_embed = test(model, test_loader_load, criterion)\n","\n","print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"]},{"cell_type":"markdown","id":"8d1bf83a","metadata":{"id":"8d1bf83a"},"source":["#### Get poems from test output and compare with orig test poems"]},{"cell_type":"code","execution_count":19,"id":"4-wN6RFOSyMB","metadata":{"id":"4-wN6RFOSyMB","executionInfo":{"status":"ok","timestamp":1649419959326,"user_tz":-180,"elapsed":9146,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["generated_poems_token = []\n","generated_poems_len = []\n","PAD_ID = token_model.subword_to_id('<PAD>')\n","BOS_ID = token_model.subword_to_id('<BOS>')\n","EOS_ID = token_model.subword_to_id('<EOS>')\n","for batch in test_poems_embed:\n","    for text_word_probab in batch:\n","        text_vocab_ids = [torch.argmax(word).item() for word in text_word_probab]\n","        generated_poems_token.append(text_vocab_ids)\n","        generated_poems_len.append(len(text_vocab_ids))\n","\n","generated_poems = token_model.decode(generated_poems_token, ignore_ids=[PAD_ID, EOS_ID]) \n","\n","orig_poems = token_model.decode(test_data_token, ignore_ids=[PAD_ID, BOS_ID, EOS_ID]) "]},{"cell_type":"code","execution_count":22,"id":"2749fe1c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":474,"status":"ok","timestamp":1649420036667,"user":{"displayName":"Вика","userId":"07891139911062556455"},"user_tz":-180},"id":"2749fe1c","outputId":"8e718459-ea79-4506-e634-9a25ca5d451d"},"outputs":[{"output_type":"stream","name":"stdout","text":["с латинского скорее челюстью своей поднимет солнце муравей скорей вода с огнем смесится к нт в ов скорее кровь в бальзам целебный обратится чем наша кончится любовь . быть может самый рим прейдет быть может т т нам вернет невозвратимого марона может может там средь над над крепкой высью пелиона и и не было богов . все допустимости во всем и иительнымительнымительным быть может быть может у может у может\n","с латинского скорее челюстью своей поднимет солнце муравей скорей вода с огнем смесится к нт в ов скорее кровь в бальзам целебный обратится чем наша кончится любовь . быть может самый рим прейдет быть может т т нам вернет невозвратимого марона быть может там средь облаков над крепкой высью пелиона и нет и не было богов . все допустимо и во всем злым и властительным умом пора быть может усомниться\n","\n","все были сказаны давно заветы сладостной свободы и прежде претворялись воды в животворящее вино . припомни брак еврейский в кане и чудо первое христа и омочи свои уста водою налитой в стакане . и если верный ученик в тебе воскреснетят прозрачный рассеет сон неволи ты станешь ты и светел . . что было светлою то сердцем сердцем в кровь претворено какое крепкое крепкое . бьет . бьет струею струею .\n","все были сказаны давно заветы сладостной свободы и прежде претворялись воды в животворящее вино . припомни брак еврейский в кане и чудо первое христа и омочи свои уста водою налитой в стакане . и если верный ученик в тебе воскреснет ток прозрачный рассеет сон неволи мрачной ты станешь светел и велик . что было светлою водою то сердцем в кровь претворено . какое крепкое вино . какою бьет оно струею .\n","\n","не ветры осыпают пущи не листопад златит холмы . с голубизны незримой кущи струятся звездные псалмы . я вижу в просиничном плате на легкокрылых облаках идет возлюбленная мати с пречичи на на руках . она мира мира мира снова распять христа кольцо ходи мой сын мой сын крова зорю ий полдню у у куста у . и в страннике я я я я я явать пойду с тоской\n","не ветры осыпают пущи не листопад златит холмы . с голубизны незримой кущи струятся звездные псалмы . я вижу в просиничном плате на легкокрылых облаках идет возлюбленная мати с пречистым сыном на руках . она несет для мира снова распять воскресшего христа ходи мой сын живи вез крова зорюй и полднюй у куста . и в каждом страннике убогом я вызнавать пойду с тоской\n","\n","на столике чай печения сдобные в серебряной вазочке драже . подобрала ноги села удобнее равнодушно спросила уже протянула руку . мои губы дотронулись до холодных гладких колец . о будущей встрече мы не условились . я знал что это конец .\n","на столике чай печения сдобные в серебряной вазочке драже . подобрала ноги села удобнее равнодушно спросила уже протянула руку . мои губы дотронулись до холодных гладких колец . о будущей встрече мы не условились . я знал что это конец .\n","\n","граждане мне начинает казаться что вы недостойны индустриализации . граждане дяди граждане тети автодора ради куда вы прете . сто ит машине распрозаявиться уже с тротуара спорхнула девица . у автомобильного у колесика остановилась длярения носика .ка объедешьдешьвою рядом рядом лу лужище с вечернейвою встал всталргргг .щий из из ноздри вори вори\n","граждане мне начинает казаться что вы недостойны индустриализации . граждане дяди граждане тети автодора ради куда вы прете . сто ит машине распрозаявиться уже с тротуара спорхнула девица . у автомобильного у колесика остановилась для пудрения носика . объедешь мостовою а рядом на лужище с вечерней москвою встал совторгслужащий . брови поднял из ноздри волось\n","\n","тот город мной любимый с детства в его декабрьской тишине моим промотанным наследством сегодня показался мне . все что само давалось в руки что было так легко отдать душевный жар молений звуки и первой песни благодать все унеслось прозрачным дымом истлело в глубине зеркал и вот уж о невозвратимоммомпапачносыйно заиграл . но с любопытствомнкинкинки плен каждойвизной нови как как санки и слушала слуша\n","тот город мной любимый с детства в его декабрьской тишине моим промотанным наследством сегодня показался мне . все что само давалось в руки что было так легко отдать душевный жар молений звуки и первой песни благодать все унеслось прозрачным дымом истлело в глубине зеркал и вот уж о невозвратимом скрипач безносый заиграл . но с любопытством иностранки плененной каждой новизной глядела я как мчатся санки и слушала\n","\n","мое прикосновенье мой сладкий поцелуй как светлое забвенье как пенье вешних струй . воздушное лобзанье до истощенья сил как сладость приказанья того кто сердцу мил . оно легко змеится вдоль тела и лица и длится длитсялитсялится как будто без конца .\n","мое прикосновенье мой сладкий поцелуй как светлое забвенье как пенье вешних струй . воздушное лобзанье до истощенья сил как сладость приказанья того кто сердцу мил . оно легко змеится вдоль тела и лица и длится длится длится как будто без конца .\n","\n","а сколько радости и неги в бегущих медленно часах . следов доискиваться в снеге взметать на лыжах белый прах . найти медвежий путь тропинку сидеть у проруби весь день пока в воде разрежет льдинку тяжелой головой тюлень . владея радостной тревогой готовый жить умереть встречать встречать уверенной остро когда подымется медведь . иватьвать под крышей снежной охра охра под под снегом и что безбре безбре безбрежный безбрежный безбре\n","а сколько радости и неги в бегущих медленно часах . следов доискиваться в снеге взметать на лыжах белый прах . найти медвежий путь тропинку сидеть у проруби весь день пока в воде разрежет льдинку тяжелой головой тюлень . владея радостной тревогой готовый жить и умереть встречать уверенной острогой когда подымется медведь . и пировать под крышей снежной и охранять под снегом челн и ждать что океан безбрежный опять\n","\n","на спичечной коробке смотри ка славный вид кораблик трехмачтовый не двигаясь бежит . не разглядишь а верно команда есть на нем и в тесном трюме в бочках изюм корица ром . и есть на нем конечно отважный капитан который видел много непостижимых стран . верно верно есть матросик что песни петь и ночью ночью звездной на небеса и глядеть и в господ господней господ на то то то то то\n","на спичечной коробке смотри ка славный вид кораблик трехмачтовый не двигаясь бежит . не разглядишь а верно команда есть на нем и в тесном трюме в бочках изюм корица ром . и есть на нем конечно отважный капитан который видел много непостижимых стран . и верно есть матросик что мастер песни петь и любит ночью звездной на небеса глядеть и я в руке господней здесь на его земле точь\n","\n","на заре ты ее не буди на заре она сладко так спит утро дышит у ней на груди ярко пышет на ямках ланит . и подушка ее горяча и горяч утомительный сон и чернеясь бегут на плеча косытойтой обе обеих сторон . а вчера у окна ввечеру долго долго сидела она следиладила тучам ту что что чтовалавала луна . чем чем ярче чем луна луна чем чем чем сви чем все соловей все ста ста ста она сердце она сердце\n","на заре ты ее не буди на заре она сладко так спит утро дышит у ней на груди ярко пышет на ямках ланит . и подушка ее горяча и горяч утомительный сон и чернеясь бегут на плеча косы лентой с обеих сторон . а вчера у окна ввечеру долго долго сидела она и следила по тучам игру что скользя затевала луна . и чем ярче играла луна и чем громче свистал соловей все бледней становилась она сердце би\n","\n"]}],"source":["for id in range(20, 30):\n","  # print(generated_poems_len[id])\n","  # print(len(orig_poems[id].split(' ')))\n","  print(generated_poems[id])\n","  print(orig_poems[id])\n","  print()"]},{"cell_type":"markdown","source":["#### Use metric to evaluate results"],"metadata":{"id":"1k5NOj3aaY6o"},"id":"1k5NOj3aaY6o"},{"cell_type":"code","source":["embedding = nn.Embedding(OUTPUT_DIM, DEC_EMB_DIM) # 1 - size of dict emb, 2 - size of emb vec\n","\n","embed_source_poems = embedding(torch.tensor(generated_poems_token)) # [poems num, word num, embed len]\n","embed_target_poems = embedding(torch.tensor(test_data_token))"],"metadata":{"id":"ZngSy1C3Epcz","colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"status":"error","timestamp":1649248384945,"user_tz":-180,"elapsed":5512,"user":{"displayName":"Вика","userId":"07891139911062556455"}},"outputId":"0d3f07f8-38c0-4a10-bb06-84d032631bf1"},"id":"ZngSy1C3Epcz","execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-a5055b0d59b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membed_source_poems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_poems_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [poems num, word num, embed len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0membed_target_poems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: expected sequence of length 20 at dim 1 (got 17)"]}]},{"cell_type":"code","source":["total_score = 0\n","for i in range(len(embed_target_poems)):\n","    embed_source_poem = embed_source_poems[i]  # [word num, embed len]\n","    embed_target_poem = embed_target_poems[i]\n","    # print(embed_source_poem.shape , embed_target_poem.shape)\n","    # print(embed_source_poem, embed_target_poem)\n","\n","    # [min, mean, max] = sentence emb-g\n","    v_s_min = torch.min(embed_source_poem)\n","    v_s_mean = torch.mean(embed_source_poem)\n","    v_s_max = torch.max(embed_source_poem)\n","\n","    v_t_min = torch.min(embed_target_poem)\n","    v_t_mean = torch.mean(embed_target_poem)\n","    v_t_max = torch.max(embed_target_poem)\n","\n","    v_s = torch.tensor([v_s_min, v_s_mean, v_s_max])\n","    v_t = torch.tensor([v_t_min, v_t_mean, v_t_max])\n","    # print(v_s, v_t)\n","\n","    score = torch.matmul(v_s.t(), v_t) / (torch.linalg.norm(v_s, ord=2) * torch.linalg.norm(v_t, ord=2))\n","    # if source = orig, then score = 1.0, else score < 1.0\n","    total_score += (1.0 - score)\n","    \n","total_score = total_score.item()\n","print(total_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9odfD-mra5P8","executionInfo":{"status":"ok","timestamp":1649086537720,"user_tz":-180,"elapsed":439,"user":{"displayName":"Вика","userId":"07891139911062556455"}},"outputId":"4081e87f-f6d4-44d7-a7d4-51d82e5eecda"},"id":"9odfD-mra5P8","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2617645263671875\n"]}]},{"cell_type":"code","source":["# print(token_model.vocab()[:30])\n","token_model.subword_to_id(' \\n')\n","token_model.encode('где бы ты не был \\n в каких бы краях . \\n я бы всегда ')\n","token_model.encode('где бы ты не был \\n в каких бы краях . \\n я бы всегда ', output_type=yttm.OutputType.SUBWORD)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7kz6aQNrDxdv","executionInfo":{"status":"ok","timestamp":1648547474209,"user_tz":-180,"elapsed":267,"user":{"displayName":"Вика","userId":"07891139911062556455"}},"outputId":"9fd20154-a012-4a29-877f-1b97abe19ef7"},"id":"7kz6aQNrDxdv","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['▁где',\n"," '▁бы',\n"," '▁ты',\n"," '▁не',\n"," '▁был',\n"," '▁в',\n"," '▁каких',\n"," '▁бы',\n"," '▁краях',\n"," '▁.',\n"," '▁я',\n"," '▁бы',\n"," '▁всегда']"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["a = torch.tensor(\n","    [\n","     [[1,2],[3,4],[5,6],[7,8]],\n","     [[0,0],[1,1],[2,2],[3,3]],\n","     [[-1,-1],[-2,-2],[-3,-3],[-4,-4]]\n","    ]\n",")\n","print(a.shape) # [3, 4, 2]\n","# в каждом стихе 3 слова, всего 4 стиха, каждое слово из 2х букв\n","\n","a = torch.transpose(a, 0, 1)\n","print(a.shape) # [4, 3, 2]\n","print(a)"],"metadata":{"id":"xwXL2dBNZYK0"},"id":"xwXL2dBNZYK0","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"test_gru_Att.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"472ff8a1e7d2494b85c3f34a0f0e7c16":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e2b495c2b584f559f10f2acd5764d95","IPY_MODEL_e6edf34e2b6b4ab4b5709c1709c5963b","IPY_MODEL_8fd9fd2e8d2843ec8e631e170a86a5bb"],"layout":"IPY_MODEL_b31f437ade0a494a89f356b4cf03b7cd"}},"9e2b495c2b584f559f10f2acd5764d95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_550442da8825482ea3634146c41bbe96","placeholder":"​","style":"IPY_MODEL_9b3d2b0f7e48469d9b808b1d35ec5955","value":"100%"}},"e6edf34e2b6b4ab4b5709c1709c5963b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd7acc15e6174849825aa184db3873ad","max":56,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7b41ab5faafe4909a06db0c8f4d7a9bf","value":56}},"8fd9fd2e8d2843ec8e631e170a86a5bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54ec14605477492fa01f771565402aef","placeholder":"​","style":"IPY_MODEL_19dacdf2a08c446bb4473d32f4522e7b","value":" 56/56 [03:20&lt;00:00,  3.11s/it]"}},"b31f437ade0a494a89f356b4cf03b7cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"550442da8825482ea3634146c41bbe96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b3d2b0f7e48469d9b808b1d35ec5955":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd7acc15e6174849825aa184db3873ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b41ab5faafe4909a06db0c8f4d7a9bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54ec14605477492fa01f771565402aef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19dacdf2a08c446bb4473d32f4522e7b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}