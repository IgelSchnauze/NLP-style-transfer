{"cells":[{"cell_type":"code","execution_count":1,"id":"e8vkfZSUsZ9b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19079,"status":"ok","timestamp":1649960655328,"user":{"displayName":"Вика","userId":"07891139911062556455"},"user_tz":-180},"id":"e8vkfZSUsZ9b","outputId":"8a0b3bdf-d2e6-499e-cbf1-1b26be8dd8f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"id":"gzBhWOnUDOXL","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4377,"status":"ok","timestamp":1649960659692,"user":{"displayName":"Вика","userId":"07891139911062556455"},"user_tz":-180},"id":"gzBhWOnUDOXL","outputId":"6e750daa-5db4-4a61-ded8-454ba41c71ba","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting youtokentome\n","  Downloading youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 9.3 MB/s \n","\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from youtokentome) (7.1.2)\n","Installing collected packages: youtokentome\n","Successfully installed youtokentome-1.0.6\n"]}],"source":["!pip install youtokentome"]},{"cell_type":"code","execution_count":3,"id":"ab9ca873","metadata":{"id":"ab9ca873","executionInfo":{"status":"ok","timestamp":1649960667359,"user_tz":-180,"elapsed":7679,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","\n","import youtokentome as yttm\n","import numpy as np\n","\n","import random\n","import math\n","import time\n","import pickle\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":4,"id":"b6018908","metadata":{"id":"b6018908","executionInfo":{"status":"ok","timestamp":1649960667360,"user_tz":-180,"elapsed":24,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":5,"id":"f92d980d","metadata":{"id":"f92d980d","executionInfo":{"status":"ok","timestamp":1649960668223,"user_tz":-180,"elapsed":886,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# device = torch.device('cpu')"]},{"cell_type":"code","execution_count":6,"id":"3089450a","metadata":{"id":"3089450a","executionInfo":{"status":"ok","timestamp":1649960668224,"user_tz":-180,"elapsed":10,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["# token_model = yttm.BPE(model='try_poems_embed_yttm.model', n_threads=-1)\n","token_model = yttm.BPE(model='/content/drive/MyDrive/Colab Notebooks/NLP_poems/voc10k_poems_embed_yttm.model', n_threads=-1)"]},{"cell_type":"code","execution_count":7,"id":"ca3d5413","metadata":{"id":"ca3d5413","executionInfo":{"status":"ok","timestamp":1649960668225,"user_tz":-180,"elapsed":9,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["class newDataset(Dataset):\n","    def __init__(self, data_list_of_list):\n","        self.data = data_list_of_list\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        return self.data[index]\n","\n","    def cut_length(self, limit):\n","#         middle_len = sum([len(text) for text in self.data])/len(self.data)\n","#         limit = int(middle_len)*2\n","        self.data = [text if len(text)<limit else text[:limit] for text in self.data]\n","\n","    def distribute_data(self, share_tr, share_val):  # examle = (0.8, 0.1)\n","        rand_i = np.random.permutation(len(self.data))\n","        n1 = int(len(self.data) * share_tr)\n","        n2 = int(len(self.data) * share_val)\n","        # return self.data[rand_i[0: n1]], self.data[rand_i[n1: n1 + n2]], self.data[rand_i[n1 + n2:]]\n","        return [self.data[i] for i in rand_i[0: n1]], \\\n","               [self.data[i] for i in rand_i[n1: n1 + n2]], \\\n","               [self.data[i] for i in rand_i[n1 + n2:]]\n","    \n","def padding(batch):\n","    pad_id = token_model.subword_to_id('<PAD>')\n","    \n","    batch = [torch.tensor(x) for x in batch]\n","    batch = pad_sequence(batch, batch_first=False, padding_value=pad_id)  # batch_first=True -> [batch size, len]\n","    return batch\n","    # return batch.to(device)\n","\n","def sort_padding(batch):\n","    pad_id = token_model.subword_to_id('<PAD>')\n","    \n","    batch.sort(key = lambda x : -len(x)) # first longest\n","\n","    batch_lens = [torch.tensor(len(x)) for x in batch]\n","    batch = [torch.tensor(x) for x in batch]\n","    batch = pad_sequence(batch, batch_first=False, padding_value=pad_id)  # batch_first=True -> [batch size, len]\n","    return batch, torch.tensor(batch_lens)"]},{"cell_type":"code","execution_count":8,"id":"04f0c0b2","metadata":{"id":"04f0c0b2","executionInfo":{"status":"ok","timestamp":1649960668551,"user_tz":-180,"elapsed":14,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        \n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        \n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        \n","        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers) # dropout = dropout\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src, src_nopad_len):      \n","        #src = [src len, batch size]\n","        \n","        embedded = self.dropout(self.embedding(src))\n","        #embedded = [src len, batch size, emb dim]\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_nopad_len.to('cpu'))\n","                \n","        packed_outputs, hidden = self.rnn(packed_embedded)\n","        #packed_outputs is a packed sequence containing all hidden states\n","        #hidden is now from the final non-padded element in the batch\n","            \n","        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n","        #outputs is now a non-packed sequence\n","        \n","        #outputs = [src len, batch size, hid dim]\n","        #hidden = [n layers, batch size, hid dim]\n","        \n","        #outputs are always from the top hidden layer\n","        #hidden - it will be first hid states in decoder\n","        return outputs, hidden"]},{"cell_type":"code","source":["class Attention(nn.Module):\n","    def __init__(self, hid_dim):\n","        super().__init__()\n","        \n","        self.attn = nn.Linear(hid_dim * 2, hid_dim)\n","        self.v = nn.Linear(hid_dim, 1, bias = False)\n","        \n","    def forward(self, hidden, encoder_outputs, mask):\n","        \n","        #hidden = [batch size, hid dim]\n","        #encoder_outputs = [src len, batch size, hid dim]\n","        #mask = [batch size, src len]  \n","        # example: sent=['hello', <pad>, <pad>], mask=[1,0,0]\n","        \n","        batch_size = encoder_outputs.shape[1]\n","        src_len = encoder_outputs.shape[0]\n","        \n","        #repeat decoder hidden state src_len times\n","        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        #hidden = [batch size, src len, hid dim]\n","        #encoder_outputs = [batch size, src len, hid dim]\n","        \n","        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n","        #energy = [batch size, src len, hid dim]\n","\n","        attention = self.v(energy).squeeze(2)\n","        attention = attention.masked_fill(mask == 0, -1e10)\n","        #attention= [batch size, src len]\n","        \n","        return F.softmax(attention, dim=1)"],"metadata":{"id":"N7n7rHfqF90n","executionInfo":{"status":"ok","timestamp":1649960668552,"user_tz":-180,"elapsed":14,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"id":"N7n7rHfqF90n","execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":10,"id":"e524e3a2","metadata":{"id":"e524e3a2","executionInfo":{"status":"ok","timestamp":1649960668553,"user_tz":-180,"elapsed":13,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout, attention):\n","        super().__init__()\n","        \n","        self.output_dim = output_dim  # the size of the vocabulary for the output/target.\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","\n","        self.attention = attention\n","        \n","        self.embedding = nn.Embedding(output_dim, emb_dim) # 1 - size of dict emb, 2 - size of emb vec\n","        \n","        self.rnn = nn.GRU(hid_dim + emb_dim, hid_dim, n_layers) # dropout = dropout\n","        \n","        self.fc_out = nn.Linear(hid_dim * 2 + emb_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden, encoder_outputs, mask):\n","\n","        #input = [batch size]\n","        #hidden = [n layers, batch size, hid dim]\n","        #encoder_outputs = [src len, batch size, hid dim]\n","        \n","        input = input.unsqueeze(0) \n","        #input = [1, batch size]\n","        embedded = self.dropout(self.embedding(input))\n","        #embedded = [1, batch size, emb dim]\n","                \n","        last_hidden = hidden[-1]\n","        #hidden = [batch size, hid dim]        \n","        a = self.attention(last_hidden, encoder_outputs, mask)    \n","        #a = [batch size, src len]\n","        a = a.unsqueeze(1)\n","        #a = [batch size, 1, src len]\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        #encoder_outputs = [batch size, src len, hid dim]\n","        \n","        weighted = torch.bmm(a, encoder_outputs)    \n","        #weighted = [batch size, 1, hid dim]\n","        weighted = weighted.permute(1, 0, 2)\n","        #weighted = [1, batch size, enc hid dim]\n","        \n","        rnn_input = torch.cat((embedded, weighted), dim = 2)\n","        #rnn_input = [1, batch size, hid dim + emb dim]\n","        \n","        output, hidden = self.rnn(rnn_input, hidden)\n","        #output = [1, batch size, hid dim], seq len will always be 1 in the decoder\n","        #hidden = [n layers, batch size, hid dim]\n","        \n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted = weighted.squeeze(0)\n","        \n","        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n","        #prediction = [batch size, output dim]\n","        \n","        return prediction, hidden"]},{"cell_type":"code","execution_count":11,"id":"c49c37e0","metadata":{"id":"c49c37e0","executionInfo":{"status":"ok","timestamp":1649960668553,"user_tz":-180,"elapsed":12,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, src_pad_idx, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_pad_idx = src_pad_idx\n","        self.device = device\n","\n","    def create_mask(self, src):\n","        mask = (src != self.src_pad_idx).permute(1, 0)\n","        return mask\n","        \n","    def forward(self, src, src_nopad_len, trg, teacher_forcing_ratio = 0.2):\n","        \n","        #src = [src len, batch size]\n","        #src_nopad_len = [batch size]\n","        #trg = [trg len, batch size]\n","        #teacher_forcing_ratio=0.75 -> use ground-truth inputs 75% of the time\n","        \n","        batch_size = trg.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","        \n","        #encoder_outputs is all hidden states of the input sequence\n","        #hidden is the final hidden states, passed through a linear layer\n","        encoder_outputs, hidden = self.encoder(src, src_nopad_len)\n","        \n","        #first input to the decoder is the <bos> tokens\n","        input = trg[0,:]  \n","        mask = self.create_mask(src)\n","        #mask = [batch size, src len]\n","        \n","        for t in range(1, trg_len):\n","            \n","            #insert input token emb-g, previous hidden state and all encoder hidden states\n","            #receive output tensor (predictions) and new hidden state\n","            output, hidden = self.decoder(input, hidden, encoder_outputs, mask)\n","            \n","            outputs[t] = output\n","            \n","            teacher_force = random.random() < teacher_forcing_ratio\n","            \n","            #get the highest predicted token\n","            top1 = output.argmax(1) \n","            \n","            #if teacher forcing, use actual next token, else use predicted token\n","            input = trg[t] if teacher_force else top1\n","        \n","        return outputs"]},{"cell_type":"code","execution_count":12,"id":"6c03553f","metadata":{"id":"6c03553f","executionInfo":{"status":"ok","timestamp":1649960668892,"user_tz":-180,"elapsed":349,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["INPUT_DIM = token_model.vocab_size() \n","OUTPUT_DIM = INPUT_DIM\n","ENC_EMB_DIM = 128 #128\n","DEC_EMB_DIM = 128 #128\n","HID_DIM = 256 #256\n","N_LAYERS = 2 \n","ENC_DROPOUT = 0.2\n","DEC_DROPOUT = 0.2\n","PAD_ID = token_model.subword_to_id('<PAD>')\n","\n","attn = Attention(HID_DIM)\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT, attn)\n","\n","model = Seq2Seq(enc, dec, PAD_ID, device).to(device)"]},{"cell_type":"code","execution_count":13,"id":"a28baf9d","metadata":{"id":"a28baf9d","executionInfo":{"status":"ok","timestamp":1649960668894,"user_tz":-180,"elapsed":12,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["PAD_ID = token_model.subword_to_id('<PAD>')\n","criterion = nn.CrossEntropyLoss(ignore_index = PAD_ID)"]},{"cell_type":"code","execution_count":14,"id":"IJQffBFbO4kw","metadata":{"id":"IJQffBFbO4kw","executionInfo":{"status":"ok","timestamp":1649960668895,"user_tz":-180,"elapsed":12,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["def test(model, loader, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    outputs_list = []\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(tqdm(loader)):\n","            batch_src = batch[0].to(device, non_blocking=True)\n","            src, src_nopad_len = batch_src, batch[1]\n","            trg = batch_src\n","\n","            output = model(src, src_nopad_len, trg, 0) #turn off teacher forcing\n","            outputs_list.append(torch.transpose(output, 0, 1))\n","\n","            #trg = [trg len, batch size]\n","            #output = [trg len, batch size, output dim]\n","\n","            output_dim = output.shape[-1]\n","\n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            #trg = [(trg len - 1) * batch size]\n","            #output = [(trg len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, trg)\n","            \n","            epoch_loss += loss.item()\n","      \n","    return epoch_loss / len(loader), outputs_list"]},{"cell_type":"code","source":["# optimizer.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/NLP_poems/b7e10dr03_optim.pt'))\n","# print(optimizer.param_groups[0]['lr'])\n","# print(optimizer.param_groups[0]['initial_lr'])\n","# print(optimizer.param_groups)"],"metadata":{"id":"NdaSGo5KZgDN","executionInfo":{"status":"ok","timestamp":1649960668896,"user_tz":-180,"elapsed":12,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"id":"NdaSGo5KZgDN","execution_count":15,"outputs":[]},{"cell_type":"code","execution_count":16,"id":"4v_oHkIGWHGB","metadata":{"id":"4v_oHkIGWHGB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649960670439,"user_tz":-180,"elapsed":1554,"user":{"displayName":"Вика","userId":"07891139911062556455"}},"outputId":"332d3418-de19-4a23-e682-7b77e1b087c2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":16}],"source":["# checkpoint = torch.load('trylr005_17k_checkpoint.pt')\n","checkpoint = torch.load('/content/drive/MyDrive/Colab Notebooks/NLP_poems/AdamW_one_C005_same_drEm2_voc10k_tf2_20406080len100_AttPad_checkp_last.pt', \n","                        map_location=torch.device('cpu'))\n","model.load_state_dict(checkpoint['model_state_dict'])"]},{"cell_type":"code","execution_count":17,"id":"6d0b297f","metadata":{"id":"6d0b297f","executionInfo":{"status":"ok","timestamp":1649960670906,"user_tz":-180,"elapsed":475,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["# with open('data/try_test_data_token.pickle', 'rb', ) as file:\n","with open('/content/drive/MyDrive/Colab Notebooks/NLP_poems/data/voc10klen100_test_data_token.pickle', 'rb', ) as file:\n","    test_data_token = pickle.load(file)\n","test_loader_load = DataLoader(\n","    test_data_token, batch_size=32, shuffle=False, num_workers=1, pin_memory=True, collate_fn=sort_padding)"]},{"cell_type":"code","execution_count":18,"id":"6c4fe1ca","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["9839d10206094282a294384420c8bccc","125d6f5fad9242b7ba2f7c18806b489f","73ccc3596b5e4bf5af97d29ebd6941d9","38988eb5d60843c79acedd900021cefc","74f3bb57f29640618c6ced30833ffc68","d143ca004fc44c7f88a69f424e9613f8","b3ac063cb7d545ef9639f8cdd9575019","bd13bd53624142d8bf44a058e5517e5e","abbce8bde6514586b8041a1595a2183e","4912f9302eba4b3fbc10283c9b7b13bc","7b100b18a23a4a08960e08ff7de6d399"]},"executionInfo":{"elapsed":218222,"status":"ok","timestamp":1649960895590,"user":{"displayName":"Вика","userId":"07891139911062556455"},"user_tz":-180},"id":"6c4fe1ca","outputId":"430a4275-85b5-492a-da52-098eaed2e2b1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/56 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9839d10206094282a294384420c8bccc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["| Test Loss: 1.116 | Test PPL:   3.053 |\n"]}],"source":["test_loss, test_poems_embed = test(model, test_loader_load, criterion)\n","\n","print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"]},{"cell_type":"markdown","id":"8d1bf83a","metadata":{"id":"8d1bf83a"},"source":["#### Get poems from test output and compare with orig test poems"]},{"cell_type":"code","execution_count":19,"id":"4-wN6RFOSyMB","metadata":{"id":"4-wN6RFOSyMB","executionInfo":{"status":"ok","timestamp":1649961048938,"user_tz":-180,"elapsed":12794,"user":{"displayName":"Вика","userId":"07891139911062556455"}}},"outputs":[],"source":["generated_poems_token = []\n","generated_poems_len = []\n","PAD_ID = token_model.subword_to_id('<PAD>')\n","BOS_ID = token_model.subword_to_id('<BOS>')\n","EOS_ID = token_model.subword_to_id('<EOS>')\n","for batch in test_poems_embed:\n","    for text_word_probab in batch:\n","        text_vocab_ids = [torch.argmax(word).item() for word in text_word_probab]\n","        generated_poems_token.append(text_vocab_ids)\n","        generated_poems_len.append(len(text_vocab_ids))\n","\n","generated_poems = token_model.decode(generated_poems_token, ignore_ids=[PAD_ID, EOS_ID]) \n","\n","test_data_token.sort(key = lambda x : -len(x)) # !!!first longest \n","orig_poems = token_model.decode(test_data_token, ignore_ids=[PAD_ID, BOS_ID, EOS_ID]) "]},{"cell_type":"code","execution_count":23,"id":"2749fe1c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1649961295583,"user":{"displayName":"Вика","userId":"07891139911062556455"},"user_tz":-180},"id":"2749fe1c","outputId":"9a1a8032-6691-4cd2-d93a-b5b8bb5cb1b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["над самой бездной на высоте уздой железной россию поднял на дыбы пушкин город змеи и медного всадниканана и иевскогоского ныне единый единый единый отребовбов до палисадника от островов до шумногоногоскогоьюьюью .ной . в в виденья виденьяжитжитыыыыымдодовыхмамамапопопо душная мгла крыла крыла крыла ж ж ж в в новом тот новом тот же же же же же же же же же\n","над самой бездной на высоте уздой железной россию поднял на дыбы пушкин город змеи и медного всадника пушкина город и достоевского ныне вчера вечно единый от небоскребов до палисадника от островов до шумного невского мощью петра тайной змеиной . в прошлом виденья прожиты отжиты драм бредовых кошмарных нелепостей душная мгла крыла злодейства что ж . в веке новом тот же ты тот же ты . те же твердыни\n","\n","на губках смех в сердечке благодать которую ни светских правил стужа ни мненья лед не властны заковать . как сладко жить как сладко сладковатьвать в семнадцать лет подрымрымрым . то ка кавал кавал цветок то то нетясь под подся к з злым зм о твердит о долге . и . и и упря упрямый упрямыйток густых волос этим дет дет дет ухом . сладко жить сладко житьааааа при\n","на губках смех в сердечке благодать которую ни светских правил стужа ни мненья лед не властны заковать . как сладко жить . как сладко танцевать в семнадцать лет под добрым взглядом мужа . то кавалеру даст смеясь цветок то не смутясь подсядет к злым старухам твердит о долге теребя платок . и страшно мил упрямый завиток густых волос над этим детским ухом . как сладко жить удачен туалет прическа\n","\n","только русский знавший с детства тяжесть вечной духоты с жизнью ваявший как наследство дедов страстные мечты тот кто выпил полной нашей прошлойлой му муть безстваства к к новой вольностистикнутькнуть . мыгаем . да мы ди ди ди ди грубо наш народ наш ведь над ним над нимлилилили но когда в когда в шум слышишь слышишь слышишь буйный крик крик вник в терпелипелипели новый новый новый язык язык ты язык\n","только русский знавший с детства тяжесть вечной духоты с жизнью ваявший как наследство дедов страстные мечты тот кто выпил полной чашей нашей прошлой правды муть без притворства может к нашей новой вольности примкнуть . мы пугаем . да мы дики тесан грубо наш народ ведь века над ним владыки простирали тяжкий гнет но когда в толпе шумливой слышишь брань и буйный крик вникни думой терпеливой в новый пламенный язык . ты расс\n","\n","я инок темный нищ и гол мне был глагол как гром огромный когда качая воздух дол взошел на тверди гром громный я я душ и я твой дом дом исполни мой завет я небесный лавьвьнная из из из муж муж он он длань простер и и мне изил и же же пернана светом . со мною . . я . я огне . . . . завет . своим своимклоклоченным крыломным крылом прог моря и моря и\n","я инок темный нищ и гол мне был глагол как гром огромный когда качая воздух дол взошел на тверди облак громный я двери душ и я твой дом . исполни мой завет небесный я лавь испуганная зрел из молний вышел муж чудесный он длань простер и очи мне пронзил и жег пернатым светом . со мною бог . я как в огне . внемлю пророческим заветам . своим всклокоченным крылом он проогнил моря и\n","\n","посв . а курсинскому летит земля на крыльях духа тьмы летит навстречу солнцу и и и и наш и и мы мы мы стремимся к солнцу . еще в душе глядят глядят глаза нея нея полуно полуночи еще еще звучат как отзвук голоса гремеме в полуно полуно полуночи но рядом с рядом ней силуэтэ ма ма ма ма ма манящий новый новый из шлет ответ ответный гимн ма ма ма ма маня . . и с тобой мой мой мой мой\n","посв . а курсинскому летит земля на крыльях духа тьмы летит навстречу солнцу и сонный город и наш путь и мы и мы стремимся к солнцу . еще в душе глядят ее глаза неясное виденье полуночи . еще звучат как отзвук голоса гремевшие в минуту полуночи . но рядом с ней забытый силуэт забытый лик магически манящий и новый хор из дали шлет ответ невнятный гимн магически манящий . и мы с тобой мой брат мой\n","\n","будешь помнить прогремела мне насмешка посидона . коней бурных он направил в глубь взволнованного лона в свой коралловый чертог . но но всемрамрамставилтьть над морем гневный бог плещут ме меска я э э эр эр свирепыйт зверьрей и и интнтнт шумные шум буруручитчит со мной мойлыйлыйт . все ж со мною со левтететеное покрывало вопли деву деву деву\n","будешь помнить прогремела мне насмешка посидона . коней бурных он направил в глубь взволнованного лона в свой коралловый чертог . но всем ветрам предоставил выть над морем гневный бог плещут мечут пеной белой ярый эвр свирепый нот зверь борей и зефир юный понт на шумные буруны мчит со мной мой утлый плот . все ж со мною левкотеи неземное покрывало деву мудрости афи\n","\n","он был в краю святом на холмах палестины . стальной его шелом иссеклицицины . он он в край святой цветущие ланиты он он домой плешивый и избитый . неверных он громил обеми руками руками ни их их не щадил ма малых с с с с встречаясь с ним смуща смущалися красотки он он их их раз перебирая четки . он он свой дом свой дом без без и без детей глядит детей\n","он был в краю святом на холмах палестины . стальной его шелом иссекли сарацины . понес он в край святой цветущие ланиты вернулся он домой плешивый и избитый . неверных он громил обеими руками ни жен их не щадил ни малых с стариками . встречаясь с ним подчас смущалися красотки он п их не раз перебирая четки . вернулся он в свой дом без славы и без злата глядит детей со\n","\n","я еду . на небе высоко плывет уж бледная луна и от селенья недалеко дорога старая видна . и по дорогебибитой звонки проезжих не гудят лишь лишь ракиты по сторонам ее ее стоят и за за них глядят уж уж полус стол стол столбы да одино одинокая без упо и и и и и и святынею своею могилы той сторожит лишь лишь лишь над над над нею ряд ра ра ра раит и есть и естьстистистисти\n","я еду . на небе высоко плывет уж бледная луна и от селенья недалеко дорога старая видна . и по дороге неизбитой звонки проезжих не гудят и лишь таинственно ракиты по сторонам ее стоят и из за них глядят уныло уж полусгнившие столбы да одинокая могила без упованья и мольбы . и крест святынею своею могилы той не сторожит лишь наклонившися над нею угрюмо шепчет ряд ракит . и есть в окрестности преда\n","\n","любим калифом иоанн ему что день почет и ласка к делам прав прав призван лишь один один из пора порабощенного дамаска . его властелин поставил и судитьитьитьитьить градомдом ним ним беседует один он ним ним сидит ве рядом окружены двор двор дворцын са са саюю блещут из блещутцыцы стены янта янта янта янта полднедневный зной и тень и тень наве навесы шелком в узор в узорных в в\n","любим калифом иоанн ему что день почет и ласка к делам правления призван лишь он один из христиан порабощенного дамаска . его поставил властелин и суд рядить и править градом он с ним беседует один он с ним сидит в совете рядом окружены его дворцы благоуханными садами лазурью блещут изразцы убраны стены янтарями в полдневный зной приют и тень дают навесы шелком тканы в узорных банях\n","\n","герои рабочий стали орлы из рабов . отчего . спроси рабочего .мемеец если знамя знамя рдеется если люди до до до света света дело дело красноармейца опорыры совета . . эх эх . потруру для дела дела рука .ка . матрос потрудился вбре я я день ночь ночьевевяяяяяячичичи стро стропицыцы золотом знамя рас знамя . ка . . . . . . . . . . . .\n","герои рабочий стали орлы из рабов . отчего . спроси рабочего . красноармеец если красное знамя рдеется если люди дорвались до света это дело красноармейца первой опоры совета . батрак эх . и потрудилась для дела свобод рука батрака . матрос потрудился в октябре я день и ночь буржуев брея . швея довольно купчихам строчить тряпицы . золотом знамя теперь расшей ка . октябрь идет пора торопиться . вперед швейка .\n","\n"]}],"source":["for id in range(0, 10):\n","  # print(generated_poems_len[id])\n","  # print(len(orig_poems[id].split(' ')))\n","  print(generated_poems[id])\n","  print(orig_poems[id])\n","  print()"]},{"cell_type":"markdown","source":["#### Use metric to evaluate results"],"metadata":{"id":"1k5NOj3aaY6o"},"id":"1k5NOj3aaY6o"},{"cell_type":"code","source":["embedding = nn.Embedding(OUTPUT_DIM, DEC_EMB_DIM) # 1 - size of dict emb, 2 - size of emb vec\n","\n","embed_source_poems = embedding(torch.tensor(generated_poems_token)) # [poems num, word num, embed len]\n","embed_target_poems = embedding(torch.tensor(test_data_token))"],"metadata":{"id":"ZngSy1C3Epcz","colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"status":"error","timestamp":1649248384945,"user_tz":-180,"elapsed":5512,"user":{"displayName":"Вика","userId":"07891139911062556455"}},"outputId":"0d3f07f8-38c0-4a10-bb06-84d032631bf1"},"id":"ZngSy1C3Epcz","execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-a5055b0d59b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membed_source_poems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_poems_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [poems num, word num, embed len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0membed_target_poems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: expected sequence of length 20 at dim 1 (got 17)"]}]},{"cell_type":"code","source":["total_score = 0\n","for i in range(len(embed_target_poems)):\n","    embed_source_poem = embed_source_poems[i]  # [word num, embed len]\n","    embed_target_poem = embed_target_poems[i]\n","    # print(embed_source_poem.shape , embed_target_poem.shape)\n","    # print(embed_source_poem, embed_target_poem)\n","\n","    # [min, mean, max] = sentence emb-g\n","    v_s_min = torch.min(embed_source_poem)\n","    v_s_mean = torch.mean(embed_source_poem)\n","    v_s_max = torch.max(embed_source_poem)\n","\n","    v_t_min = torch.min(embed_target_poem)\n","    v_t_mean = torch.mean(embed_target_poem)\n","    v_t_max = torch.max(embed_target_poem)\n","\n","    v_s = torch.tensor([v_s_min, v_s_mean, v_s_max])\n","    v_t = torch.tensor([v_t_min, v_t_mean, v_t_max])\n","    # print(v_s, v_t)\n","\n","    score = torch.matmul(v_s.t(), v_t) / (torch.linalg.norm(v_s, ord=2) * torch.linalg.norm(v_t, ord=2))\n","    # if source = orig, then score = 1.0, else score < 1.0\n","    total_score += (1.0 - score)\n","    \n","total_score = total_score.item()\n","print(total_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9odfD-mra5P8","executionInfo":{"status":"ok","timestamp":1649086537720,"user_tz":-180,"elapsed":439,"user":{"displayName":"Вика","userId":"07891139911062556455"}},"outputId":"4081e87f-f6d4-44d7-a7d4-51d82e5eecda"},"id":"9odfD-mra5P8","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2617645263671875\n"]}]},{"cell_type":"code","source":["# print(token_model.vocab()[:30])\n","token_model.subword_to_id(' \\n')\n","token_model.encode('где бы ты не был \\n в каких бы краях . \\n я бы всегда ')\n","token_model.encode('где бы ты не был \\n в каких бы краях . \\n я бы всегда ', output_type=yttm.OutputType.SUBWORD)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7kz6aQNrDxdv","executionInfo":{"status":"ok","timestamp":1648547474209,"user_tz":-180,"elapsed":267,"user":{"displayName":"Вика","userId":"07891139911062556455"}},"outputId":"9fd20154-a012-4a29-877f-1b97abe19ef7"},"id":"7kz6aQNrDxdv","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['▁где',\n"," '▁бы',\n"," '▁ты',\n"," '▁не',\n"," '▁был',\n"," '▁в',\n"," '▁каких',\n"," '▁бы',\n"," '▁краях',\n"," '▁.',\n"," '▁я',\n"," '▁бы',\n"," '▁всегда']"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["a = torch.tensor(\n","    [\n","     [[1,2],[3,4],[5,6],[7,8]],\n","     [[0,0],[1,1],[2,2],[3,3]],\n","     [[-1,-1],[-2,-2],[-3,-3],[-4,-4]]\n","    ]\n",")\n","print(a.shape) # [3, 4, 2]\n","# в каждом стихе 3 слова, всего 4 стиха, каждое слово из 2х букв\n","\n","a = torch.transpose(a, 0, 1)\n","print(a.shape) # [4, 3, 2]\n","print(a)"],"metadata":{"id":"xwXL2dBNZYK0"},"id":"xwXL2dBNZYK0","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"test_gru_AttPad.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"9839d10206094282a294384420c8bccc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_125d6f5fad9242b7ba2f7c18806b489f","IPY_MODEL_73ccc3596b5e4bf5af97d29ebd6941d9","IPY_MODEL_38988eb5d60843c79acedd900021cefc"],"layout":"IPY_MODEL_74f3bb57f29640618c6ced30833ffc68"}},"125d6f5fad9242b7ba2f7c18806b489f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d143ca004fc44c7f88a69f424e9613f8","placeholder":"​","style":"IPY_MODEL_b3ac063cb7d545ef9639f8cdd9575019","value":"100%"}},"73ccc3596b5e4bf5af97d29ebd6941d9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd13bd53624142d8bf44a058e5517e5e","max":56,"min":0,"orientation":"horizontal","style":"IPY_MODEL_abbce8bde6514586b8041a1595a2183e","value":56}},"38988eb5d60843c79acedd900021cefc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4912f9302eba4b3fbc10283c9b7b13bc","placeholder":"​","style":"IPY_MODEL_7b100b18a23a4a08960e08ff7de6d399","value":" 56/56 [03:37&lt;00:00,  3.55s/it]"}},"74f3bb57f29640618c6ced30833ffc68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d143ca004fc44c7f88a69f424e9613f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3ac063cb7d545ef9639f8cdd9575019":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd13bd53624142d8bf44a058e5517e5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abbce8bde6514586b8041a1595a2183e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4912f9302eba4b3fbc10283c9b7b13bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b100b18a23a4a08960e08ff7de6d399":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}