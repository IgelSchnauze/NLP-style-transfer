{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8vkfZSUsZ9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:37.138740Z",
     "start_time": "2022-05-16T20:59:37.120073Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2599,
     "status": "ok",
     "timestamp": 1651063728987,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "e8vkfZSUsZ9b",
    "outputId": "7948a401-2f25-4a93-8e2e-6763856e3ff4"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gzBhWOnUDOXL",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:37.170749Z",
     "start_time": "2022-05-16T20:59:37.141638Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6765,
     "status": "ok",
     "timestamp": 1651063735748,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "gzBhWOnUDOXL",
    "outputId": "62d90d2c-fab6-4b43-df5d-6a8fc99de710",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install youtokentome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab9ca873",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:40.107271Z",
     "start_time": "2022-05-16T20:59:37.172747Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1651063735749,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "ab9ca873"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import youtokentome as yttm\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6018908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:40.145884Z",
     "start_time": "2022-05-16T20:59:40.127835Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1651063735750,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "b6018908"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f92d980d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:40.186997Z",
     "start_time": "2022-05-16T20:59:40.147895Z"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1651063735750,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "f92d980d"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3089450a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:40.296816Z",
     "start_time": "2022-05-16T20:59:40.189112Z"
    },
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1651063736348,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "3089450a"
   },
   "outputs": [],
   "source": [
    "token_model = yttm.BPE(model='models/100k_voc20k_all_embed_yttm.model', n_threads=-1)\n",
    "# token_model = yttm.BPE(model='/content/drive/MyDrive/Colab Notebooks/NLP_poems/models/100k_voc20k_all_embed_yttm.model', n_threads=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca3d5413",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:40.312904Z",
     "start_time": "2022-05-16T20:59:40.297826Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1651063736349,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "ca3d5413"
   },
   "outputs": [],
   "source": [
    "class styleDataset(Dataset):\n",
    "    def __init__(self, data_list_of_list):\n",
    "        self.data = data_list_of_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def cut_length(self, limit):\n",
    "        self.data = [text if len(text)<limit else text[:limit] for text in self.data]\n",
    "\n",
    "    def distribute_data(self, share_tr, share_val):  # examle = (0.8, 0.1)\n",
    "        rand_i = np.random.permutation(len(self.data))\n",
    "        n1 = int(len(self.data) * share_tr)\n",
    "        n2 = int(len(self.data) * share_val)\n",
    "        return [self.data[i] for i in rand_i[0: n1]], \\\n",
    "               [self.data[i] for i in rand_i[n1: n1 + n2]], \\\n",
    "               [self.data[i] for i in rand_i[n1 + n2:]]\n",
    "    \n",
    "def padding(batch):\n",
    "    pad_id = token_model.subword_to_id('<PAD>')\n",
    "    \n",
    "    batch = [torch.tensor(x) for x in batch]\n",
    "    batch = pad_sequence(batch, batch_first=False, padding_value=pad_id)  # batch_first=True -> [batch size, len]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f0c0b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:40.329001Z",
     "start_time": "2022-05-16T20:59:40.314907Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1651063736349,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "04f0c0b2"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, style_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.style_dim = style_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim) # 1 - size of dict emb, 2 - size of emb vec\n",
    "        self.style_embedding = nn.Embedding(2, style_dim) # 2, because 0-new, 1-poem\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim + style_dim, n_layers)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_style):      \n",
    "        #src = [src len, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "\n",
    "        style_token = torch.tensor([src_style], device=device)\n",
    "\n",
    "        init_hidden = torch.cat((self.style_embedding(style_token), \n",
    "                                torch.zeros((1, self.hid_dim), device=device)), dim=1)\n",
    "        init_hidden = init_hidden.repeat(self.n_layers, src.shape[1], 1) \n",
    "        #init hidden = [n layers, batch size, style dim + hid_dim]\n",
    "\n",
    "        outputs, hidden = self.rnn(embedded, init_hidden)\n",
    "        #outputs = [src len, batch size, style dim + hid dim]\n",
    "        #hidden = [n layers, batch size, style dim + hid dim]\n",
    "        \n",
    "        #pop style part\n",
    "        outputs = outputs[:,:, self.style_dim:]\n",
    "        hidden = hidden[:,:, self.style_dim:]\n",
    "        #outputs = [src len, batch size, hid dim]\n",
    "        #hidden = [n layers, batch size, hid dim]\n",
    "\n",
    "        #outputs are always from the top hidden layer\n",
    "        #hidden - it will be first hid states in decoder\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f0ea421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:40.345071Z",
     "start_time": "2022-05-16T20:59:40.331003Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# style emb\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hid_dim, style_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.style_dim = style_dim\n",
    "        self.attn = nn.Linear(hid_dim * 2 + style_dim, hid_dim)\n",
    "        self.v = nn.Linear(hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        #hidden = [batch size, style dim + hid dim]\n",
    "        #encoder_outputs = [src len, batch size, hid dim]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        #hidden = [batch size, src len, style dim + hid dim]\n",
    "        #encoder_outputs = [batch size, src len, hid dim]\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        #energy = [batch size, src len, hid dim]\n",
    "\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        #attention= [batch size, src len]\n",
    "        \n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31b3bf76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:40.360625Z",
     "start_time": "2022-05-16T20:59:40.347577Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, style_dim, n_layers, dropout, attention):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim  # the size of the voc\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.style_dim = style_dim\n",
    "\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim) \n",
    "        self.style_embedding = nn.Embedding(2, style_dim)\n",
    "\n",
    "        self.rnn = nn.GRU(hid_dim + emb_dim, hid_dim + style_dim, n_layers) \n",
    "\n",
    "        self.fc_out = nn.Linear(hid_dim * 2 + emb_dim + style_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs, trg_style):\n",
    "        #input = [batch size]\n",
    "        #hidden = [n layers, batch size, style dim + hid dim]\n",
    "        #encoder_outputs = [src len, batch size, hid dim]\n",
    "        \n",
    "        input = input.unsqueeze(0) \n",
    "        #input = [1, batch size]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        #embedded = [1, batch size, emb dim]\n",
    "\n",
    "        if trg_style != -1: # make init hidden with style\n",
    "            style_token = torch.tensor([trg_style], device=device)\n",
    "            h_style = self.style_embedding(style_token)\n",
    "            h_style = h_style.repeat(self.n_layers, hidden.shape[1], 1)\n",
    "            #h_style = [n layers, batch size, style dim]\n",
    "\n",
    "            hidden = torch.concat((h_style, hidden), dim=2)\n",
    "                \n",
    "        last_hidden = hidden[-1]\n",
    "        #last hidden = [batch size, style dim + hid dim]        \n",
    "        a = self.attention(last_hidden, encoder_outputs)    \n",
    "        #a = [batch size, src len]\n",
    "        a = a.unsqueeze(1)\n",
    "        #a = [batch size, 1, src len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        #encoder_outputs = [batch size, src len, hid dim]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)    \n",
    "        #weighted = [batch size, 1, hid dim]\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        #weighted = [1, batch size, hid dim]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        #rnn_input = [1, batch size, hid dim + emb dim]\n",
    "\n",
    "        output, hidden = self.rnn(rnn_input, hidden)\n",
    "        #output = [1, batch size, style dim + hid dim]\n",
    "        #hidden = [n layers, batch size, style dim + hid dim]\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "#         return output, prediction, hidden\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49c37e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:40.376662Z",
     "start_time": "2022-05-16T20:59:40.362625Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 408,
     "status": "ok",
     "timestamp": 1651063736754,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "c49c37e0"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, src_style, trg_style, tf_ratio):\n",
    "        #src, trg = [src len, batch size]\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        hid_dim = self.decoder.hid_dim\n",
    "        style_dim = self.decoder.style_dim\n",
    "        \n",
    "        predictions = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "#         outputs = torch.zeros(trg_len, batch_size, hid_dim + style_dim).to(self.device)\n",
    "         \n",
    "        enc_outputs, hidden = self.encoder(src, src_style)\n",
    "            \n",
    "        #first input to the decoder is the <bos> tokens\n",
    "        input = trg[0,:]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            #insert: input token emb-g, previous hid state, all enc outputs, style\n",
    "            #receive: prediction and new hidden state\n",
    "            prediction, hidden = self.decoder(input, hidden, enc_outputs, trg_style)\n",
    "            \n",
    "            trg_style = -1 # turn off making init hidden with style\n",
    "            \n",
    "            predictions[t] = prediction\n",
    "#             outputs[t] = output \n",
    "            \n",
    "            #get the highest predicted token\n",
    "            top1 = prediction.argmax(1) \n",
    "            teacher_force = random.random() < tf_ratio\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "zM5Jog2U4msV",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:40.392711Z",
     "start_time": "2022-05-16T20:59:40.378856Z"
    },
    "code_folding": [
     0
    ],
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1651063736755,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "zM5Jog2U4msV"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, n_filters, filter_sizes, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_squeeze = nn.Linear(output_dim, emb_dim)\n",
    "\n",
    "        # in_cnannels: in images this is 3 (1 channel for each of the red, blue and green),\n",
    "        #              in text we only have a 1 channel - the text itself\n",
    "        # out_channels: the number of filters\n",
    "        # kernel_size is the size of the filters = [n x emb_dim] where n is the size of the n-grams.\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1,\n",
    "                      out_channels=n_filters,\n",
    "                      kernel_size=(fs, emb_dim)) \n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, 2) \n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, gener_predicts):\n",
    "        \n",
    "        # gener_predicts = [batch size, trg len, output dim]\n",
    "        gener_predicts = F.softmax(gener_predicts, dim=-1)\n",
    "        embedded = self.emb_squeeze(gener_predicts)\n",
    "        # embedded = [batch size, trg len, emb dim]\n",
    "\n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        # embedded = [batch size, 1, trg len, hid dim]\n",
    "\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs] # element-wise relu(x) = max(0,x)\n",
    "        # conved_n = [batch size, n_filters, trg len - filter_sizes[n] + 1]\n",
    "\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        # pooled_n = [batch size, n_filters]\n",
    "\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        # cat = [batch size, n_filters * len(filter_sizes)]\n",
    "\n",
    "        predicts = self.fc(cat) \n",
    "        # predicts = [batch size, 2]\n",
    "        # [x,y] - x bigger, then this isn't this style, y - it's this style\n",
    "        return predicts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c03553f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:52.882754Z",
     "start_time": "2022-05-16T20:59:40.394713Z"
    },
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1651063737328,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "6c03553f"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = token_model.vocab_size() \n",
    "OUTPUT_DIM = INPUT_DIM\n",
    "ENC_EMB_DIM = 128 \n",
    "DEC_EMB_DIM = 128\n",
    "STYLE_EMB_DIM = 256 \n",
    "HID_DIM = 256 \n",
    "N_LAYERS = 2 \n",
    "ENC_DROPOUT = 0.2\n",
    "DEC_DROPOUT = 0.2\n",
    "LABEL_DROPOUT = 0.3\n",
    "\n",
    "N_FILTERS = 128\n",
    "FILTER_SIZES = [1,3,4,5,8] \n",
    "\n",
    "attn = Attention(HID_DIM, STYLE_EMB_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, STYLE_EMB_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, STYLE_EMB_DIM, N_LAYERS, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "discr_poem = Discriminator(OUTPUT_DIM, HID_DIM, N_FILTERS, FILTER_SIZES, LABEL_DROPOUT).to(device) \n",
    "discr_news = Discriminator(OUTPUT_DIM, HID_DIM, N_FILTERS, FILTER_SIZES, LABEL_DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a28baf9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:52.899815Z",
     "start_time": "2022-05-16T20:59:52.883754Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1651063737328,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "a28baf9d"
   },
   "outputs": [],
   "source": [
    "PAD_ID = token_model.subword_to_id('<PAD>')\n",
    "gener_criterion = nn.CrossEntropyLoss(ignore_index = PAD_ID)\n",
    "discr_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3876423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_gener(batch, src_style):\n",
    "    batch = batch.to(device, non_blocking=True)\n",
    "    src, trg = batch, batch\n",
    "    #batch[src len, batch size]\n",
    "\n",
    "    predict_same = model(src, trg, src_style, src_style, 0)      # FREE-RUNNING\n",
    "    predict_fake = model(src, trg, src_style, 1 - src_style, 0)  # FREE-RUNNING\n",
    "    #predict_same = [trg len, batch size, output dim]\n",
    "\n",
    "    #trg = [trg len, batch size]\n",
    "    #predict = [trg len, batch size, output dim]\n",
    "    predict_dim = predict_same.shape[-1]\n",
    "    predict_same_for_loss = predict_same[1:].view(-1, predict_dim)\n",
    "    trg = trg[1:].view(-1)\n",
    "    #trg = [(trg len - 1) * batch size]\n",
    "    #predict_same_for_loss = [(trg len - 1) * batch size, output dim]\n",
    "    \n",
    "    predict_same = predict_same.permute(1, 0, 2)\n",
    "    predict_fake = predict_fake.permute(1, 0, 2)\n",
    "    #predict_same = [batch size, trg len, output dim]\n",
    "\n",
    "    return predict_same, predict_fake, predict_same_for_loss, trg, batch.shape[1]\n",
    "\n",
    "\n",
    "def test(model, discr_poem, discr_news, loader_p, loader_n, gener_criterion, discr_criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    discr_poem.eval()\n",
    "    discr_news.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "\n",
    "    acc_discr_poem_rec_right = 0 # poem discr get recon poem and told yes\n",
    "    acc_discr_news_rec_right = 0\n",
    "    acc_discr_poem_stt_is_st = 0 # poem discr get fake poem from news and told yes\n",
    "    acc_discr_news_stt_is_st = 0\n",
    "    \n",
    "    out_list_poem_recon = []\n",
    "    out_list_poem_trans = []\n",
    "    out_list_news_recon = []\n",
    "    out_list_news_trans = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch_p, batch_n in tqdm(zip(loader_p, loader_n), total=len(loader_p)):\n",
    "            # 1 epoch = 2 batchs, 1 with poem and news\n",
    "\n",
    "            p_predict_same, p_predict_fake, p_predict_same_loss, p_trg, batch_size = valid_get_gener(batch_p, 1)\n",
    "            n_predict_same, n_predict_fake, n_predict_same_loss, n_trg, _ = valid_get_gener(batch_n, 0)\n",
    "\n",
    "            ### save gener texts ###\n",
    "            p_predict_same_save = p_predict_same.argmax(2)\n",
    "            p_predict_fake_save = p_predict_fake.argmax(2)\n",
    "            n_predict_same_save = n_predict_same.argmax(2)\n",
    "            n_predict_fake_save = n_predict_fake.argmax(2)\n",
    "            #out_tokens_same = [trg len, batch size]\n",
    "\n",
    "            p_predict_same_save = p_predict_same.permute(1, 0)\n",
    "            p_predict_fake_save = p_predict_fake.permute(1, 0)\n",
    "            n_predict_same_save = n_predict_same.permute(1, 0)\n",
    "            n_predict_fake_save = n_predict_fake.permute(1, 0)\n",
    "            #out_tokens_same = [batch size, trg len]\n",
    "\n",
    "            out_list_poem_recon.append(p_predict_same_save)\n",
    "            out_list_poem_trans.append(p_predict_fake_save)\n",
    "            out_list_news_recon.append(n_predict_same_save)\n",
    "            out_list_news_trans.append(n_predict_fake_save)\n",
    "\n",
    "            # [x,y] - x bigger, then this isn't this style, y - it's this style\n",
    "            is_style = torch.ones((batch_size), device=device).long()\n",
    "            isnt_style = torch.zeros((batch_size), device=device).long()\n",
    "\n",
    "            ### generator ###\n",
    "            loss_reconstr = gener_criterion(p_predict_same_loss, p_trg) + \\\n",
    "                            gener_criterion(n_predict_same_loss, n_trg)\n",
    "\n",
    "            discr_poem_out_fake = discr_poem(n_predict_fake)\n",
    "            discr_news_out_fake = discr_news(p_predict_fake)\n",
    "\n",
    "            loss_style_trans = discr_criterion(discr_poem_out_fake, is_style) + \\\n",
    "                               discr_criterion(discr_news_out_fake, is_style)\n",
    "\n",
    "            ### discriminators ###\n",
    "            discr_poem_out_same = discr_poem(p_predict_same.detach())\n",
    "            discr_news_out_same = discr_news(n_predict_same.detach())\n",
    "\n",
    "            loss_discr_poem = discr_criterion(discr_poem_out_same, is_style) + \\\n",
    "                              discr_criterion(discr_poem_out_fake, isnt_style)\n",
    "            loss_discr_news = discr_criterion(discr_news_out_same, is_style) + \\\n",
    "                              discr_criterion(discr_news_out_fake, isnt_style)\n",
    "\n",
    "            ### accuracy ###\n",
    "            acc_discr_poem_rec_right += (discr_poem_out_same.argmax(1) == 1).sum().item()\n",
    "            acc_discr_news_rec_right += (discr_news_out_same.argmax(1) == 1).sum().item()\n",
    "\n",
    "            acc_discr_poem_stt_is_st += (discr_poem_out_fake.argmax(1) == 1).sum().item()\n",
    "            acc_discr_news_stt_is_st += (discr_news_out_fake.argmax(1) == 1).sum().item()\n",
    "\n",
    "            ### save epoch loss ###\n",
    "            epoch_loss += (loss_reconstr + loss_style_trans + loss_discr_poem + loss_discr_news)\n",
    "\n",
    "    acc_discr_poem_rec = acc_discr_poem_rec_right / len(valid_poem)\n",
    "    acc_discr_news_rec = acc_discr_news_rec_right / len(valid_poem)\n",
    "\n",
    "    acc_discr_poem_stt = acc_discr_poem_stt_is_st / len(valid_poem)\n",
    "    acc_discr_news_stt = acc_discr_news_stt_is_st / len(valid_poem)\n",
    "\n",
    "    return epoch_loss / len(loader_p) \\\n",
    "           acc_discr_poem_rec, acc_discr_news_rec, acc_discr_poem_stt, acc_discr_news_stt, \\\n",
    "           out_list_news_recon, out_list_news_trans, out_list_poem_recon, out_list_poem_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20ebb7f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:52.930929Z",
     "start_time": "2022-05-16T20:59:52.903324Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def test(model, discr_poem, discr_news, loader_p, loader_n, gener_criterion, discr_criterion):\n",
    "    \n",
    "#     model.eval()\n",
    "    \n",
    "#     epoch_loss = 0\n",
    "#     epoch_loss_gen_rec = 0\n",
    "#     epoch_loss_gen_stt = 0\n",
    "#     epoch_loss_discrs = 0\n",
    "\n",
    "#     acc_discr_poem_rec_right = 0 # poem discr get recon poem and told yes\n",
    "#     acc_discr_news_rec_right = 0\n",
    "#     acc_discr_poem_stt_is_st = 0 # poem discr get fake poem from news and told yes\n",
    "#     acc_discr_news_stt_is_st = 0\n",
    "\n",
    "#     out_list_news_recon = []\n",
    "#     out_list_news_trans = []\n",
    "#     out_list_poem_recon = []\n",
    "#     out_list_poem_trans = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "    \n",
    "#         for batch_p, batch_n in tqdm(zip(loader_p, loader_n), total=len(loader_p)):\n",
    "#             for batch, src_style in (batch_p, batch_n):\n",
    "#                 batch = batch.to(device, non_blocking=True)\n",
    "#                 src = batch\n",
    "#                 trg = batch\n",
    "\n",
    "#                 predict_same, out_tokens_same = model(src, trg, src_style, src_style, 0) #turn off teacher forcing\n",
    "#                 predict_fake, out_tokens_fake = model(src, trg, src_style, 1 - src_style, 0) \n",
    "#                 #predict_same = [trg len, batch size, output dim]\n",
    "#                 #out_tokens_same = [trg len, batch size, hid dim]\n",
    "                \n",
    "#                 out_tokens_same_old = predict_same.argmax(2)\n",
    "#                 out_tokens_fake_old = predict_fake.argmax(2)\n",
    "#                 #out_tokens_same = [trg len, batch size]\n",
    "            \n",
    "#                 out_tokens_same_old = out_tokens_same_old.permute(1, 0) \n",
    "#                 out_tokens_fake_old = out_tokens_fake_old.permute(1, 0)\n",
    "#                 #out_tokens_same = [batch size, trg len]\n",
    "\n",
    "#                 if src_style == 0: # news\n",
    "#                   out_list_news_recon.append(out_tokens_same_old)\n",
    "#                   out_list_news_trans.append(out_tokens_fake_old)\n",
    "#                 if src_style == 1: # poem\n",
    "#                   out_list_poem_recon.append(out_tokens_same_old)\n",
    "#                   out_list_poem_trans.append(out_tokens_fake_old)\n",
    "                \n",
    "#                 predict_same_for_loss = predict_same\n",
    "#                 out_tokens_same = predict_same.permute(1, 0, 2)\n",
    "#                 out_tokens_fake = predict_fake.permute(1, 0, 2)\n",
    "#                 #predict_same = [batch size, trg len, output dim]\n",
    "\n",
    "#                 is_style = torch.ones((batch.shape[1]), device=device).long()\n",
    "#                 isnt_style = torch.zeros((batch.shape[1]), device=device).long()\n",
    "\n",
    "#                 if src_style == 0: # news\n",
    "#                   discr_news_out_same = discr_news(out_tokens_same)\n",
    "#                   discr_poem_out_fake = discr_poem(out_tokens_fake)\n",
    "\n",
    "#                   loss_discr_news = discr_criterion(discr_news_out_same, is_style)\n",
    "#                   loss_discr_poem = discr_criterion(discr_poem_out_fake, isnt_style) # find fault in style transfer \n",
    "\n",
    "#                   loss_style_trans = discr_criterion(discr_poem_out_fake, is_style) # find success in style transfer\n",
    "\n",
    "#                   acc_discr_news_rec_right += (discr_news_out_same.argmax(1) == 1).sum().item()\n",
    "#                   acc_discr_poem_stt_is_st += (discr_poem_out_fake.argmax(1) == 1).sum().item()\n",
    "\n",
    "#                 if src_style == 1: # poem\n",
    "#                   discr_news_out_fake = discr_news(out_tokens_fake)\n",
    "#                   discr_poem_out_same = discr_poem(out_tokens_same)\n",
    "\n",
    "#                   loss_discr_news = discr_criterion(discr_news_out_fake, isnt_style)\n",
    "#                   loss_discr_poem = discr_criterion(discr_poem_out_same, is_style) \n",
    "\n",
    "#                   loss_style_trans = discr_criterion(discr_news_out_fake, is_style)\n",
    "\n",
    "#                   acc_discr_poem_rec_right += (discr_poem_out_same.argmax(1) == 1).sum().item()\n",
    "#                   acc_discr_news_stt_is_st += (discr_news_out_fake.argmax(1) == 1).sum().item()\n",
    "                \n",
    "#                 #trg = [trg len, batch size]\n",
    "#                 #predict = [trg len, batch size, output dim]\n",
    "#                 predict_dim = predict_same.shape[-1]\n",
    "#                 predict_same_for_loss = predict_same_for_loss[1:].view(-1, predict_dim)\n",
    "#                 trg = trg[1:].view(-1)\n",
    "#                 #trg = [(trg len - 1) * batch size]\n",
    "#                 #predict_same = [(trg len - 1) * batch size, output dim]\n",
    "                \n",
    "#                 loss_reconstr = gener_criterion(predict_same_for_loss, trg)\n",
    "\n",
    "#                 loss_generator = loss_reconstr + loss_style_trans\n",
    "#                 loss_discr = loss_discr_poem + loss_discr_news\n",
    "\n",
    "#                 loss = loss_generator + loss_discr\n",
    "\n",
    "#                 epoch_loss += loss\n",
    "#                 epoch_loss_gen_rec += loss_reconstr\n",
    "#                 epoch_loss_gen_stt += loss_style_trans\n",
    "#                 epoch_loss_discrs += loss_discr\n",
    "\n",
    "#     acc_discr_poem_rec = acc_discr_poem_rec_right / len(test_poem)\n",
    "#     acc_discr_news_rec = acc_discr_news_rec_right / len(test_poem)\n",
    "\n",
    "#     acc_discr_poem_stt = acc_discr_poem_stt_is_st / len(test_poem)\n",
    "#     acc_discr_news_stt = acc_discr_news_stt_is_st / len(test_poem)\n",
    "        \n",
    "#     return epoch_loss / len(loader_p), epoch_loss_gen_rec / len(loader_p), \\\n",
    "#            epoch_loss_gen_stt / len(loader_p), epoch_loss_discrs / len(loader_p), \\\n",
    "#            acc_discr_poem_rec, acc_discr_news_rec, \\\n",
    "#            acc_discr_poem_stt, acc_discr_news_stt, \\\n",
    "#            out_list_news_recon, out_list_news_trans, out_list_poem_recon, out_list_poem_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4v_oHkIGWHGB",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:53.984944Z",
     "start_time": "2022-05-16T20:59:52.932934Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8259,
     "status": "ok",
     "timestamp": 1651063745584,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "4v_oHkIGWHGB",
    "outputId": "9e56773f-3b4f-406e-f8b0-67184a6de462"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('ST_len40_dAdam005_genCyclefdf10_isnt1stt1-af10e0-Copy1.25rec1_discr14e_checkp_last.pt')\n",
    "# checkpoint = torch.load('/content/drive/MyDrive/Colab Notebooks/NLP_poems/ST_15k_voc20k_len20_nf100_fs2,6_Lstt3_discrCyc0.1fdf1_checkp_last.pt', \n",
    "#                         map_location=torch.device('cpu'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "discr_poem.load_state_dict(checkpoint['discr_poem_state_dict'])\n",
    "discr_news.load_state_dict(checkpoint['discr_news_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d0b297f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T20:59:54.015885Z",
     "start_time": "2022-05-16T20:59:53.985945Z"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1651063745585,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "6d0b297f"
   },
   "outputs": [],
   "source": [
    "with open('data/voc20klen40_test_poem.pickle', 'rb', ) as file:\n",
    "# with open('/content/drive/MyDrive/Colab Notebooks/NLP_poems/data/voc20klen20_test_poem.pickle', 'rb', ) as file:\n",
    "    test_poem = pickle.load(file)\n",
    "test_poem_loader = (\n",
    "    DataLoader(test_poem, batch_size=64, shuffle=False, num_workers=0, pin_memory=True, collate_fn=padding)\n",
    ")\n",
    "\n",
    "with open('data/voc20klen40_test_news.pickle', 'rb', ) as file:\n",
    "# with open('/content/drive/MyDrive/Colab Notebooks/NLP_poems/data/voc20klen20_test_news.pickle', 'rb', ) as file:\n",
    "    test_news = pickle.load(file)\n",
    "test_news_loader = (\n",
    "    DataLoader(test_news, batch_size=64, shuffle=False, num_workers=0, pin_memory=True, collate_fn=padding)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c4fe1ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T21:01:06.193011Z",
     "start_time": "2022-05-16T20:59:55.973078Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "96726c6387c8421582ca95dbbf1725a4",
      "c0a80eed03654f4286a8253856e9dc23",
      "f5889def24a54bae8cf98e4417158359",
      "efbb9250cc044a00bae22fa663fb63f7",
      "fe518ed238524213a751a4ebb61e4169",
      "d912a8318c064df0a070fa1bacf30e0c",
      "1c3379e2c91543ceb9476aa2fbb47669",
      "ca66c185131c46c3abbe16180b525717",
      "149424d11ffc42c7bdcf0aca4d0a4b2f",
      "a0c45bb7820c44aebb5f73da32bf2188",
      "65502f417cd44677b5b7e3f3f095dee4"
     ]
    },
    "executionInfo": {
     "elapsed": 117415,
     "status": "ok",
     "timestamp": 1651063869215,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "6c4fe1ca",
    "outputId": "b45fdad9-e9d0-441a-fde3-bd97e0bfc4c8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65803496ddea4ad8b84884fa45a42f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Test Loss: 8.662 | Acc recon poem: 0.80 | Acc recon news: 0.87 | Acc d_poem stt: 0.04 | Acc d_news stt: 0.03\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_loss_gen_rec, test_loss_gen_stt, test_loss_discrs, \\\n",
    "test_acc_recon_poem, test_acc_recon_news, test_acc_discr_poem_stt, test_acc_discr_news_stt, \\\n",
    "test_news_recon, test_news_trans, test_poem_recon, test_poem_trans = \\\n",
    "           test(model, discr_poem, discr_news, \n",
    "                test_poem_loader, test_news_loader, \n",
    "                gener_criterion, discr_criterion)\n",
    "\n",
    "print(f'\\t Test Loss: {test_loss:.3f} | Acc recon poem: {test_acc_recon_poem:.2f} | Acc recon news: {test_acc_recon_news:.2f} | ' +\n",
    "          f'Acc d_poem stt: {test_acc_discr_poem_stt:.2f} | Acc d_news stt: {test_acc_discr_news_stt:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1bf83a",
   "metadata": {
    "id": "8d1bf83a"
   },
   "source": [
    "#### Get poems from test output and compare with orig test poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e68f1769",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T12:22:59.269752Z",
     "start_time": "2022-05-11T12:22:59.254727Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open('data/len40_batch_gener_news-poem_recon-trans_token.pickle', 'wb', ) as file:\n",
    "# # with open('/content/drive/MyDrive/Colab Notebooks/NLP_poems/data/voc20klen20_test_news.pickle', 'wb', ) as file:\n",
    "#     pickle.dump((test_news_recon, test_news_trans, test_poem_recon, test_poem_trans), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "n4266pQ29NrM",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T21:02:35.221386Z",
     "start_time": "2022-05-16T21:02:35.194733Z"
    },
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1651063930772,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "n4266pQ29NrM"
   },
   "outputs": [],
   "source": [
    "#[num batchs, batch len, trg len]\n",
    "gener_news_recon, gener_news_trans, gener_poem_recon, gener_poem_trans = [],[],[],[]\n",
    "#in one lines all data\n",
    "\n",
    "for i in range(len(test_news_recon)):\n",
    "    gener_news_recon.extend(test_news_recon[i]) \n",
    "    gener_news_trans.extend(test_news_trans[i])\n",
    "    gener_poem_recon.extend(test_poem_recon[i])\n",
    "    gener_poem_trans.extend(test_poem_trans[i])\n",
    "\n",
    "# with open('data/len40_gener_news-poem_recon-trans_token.pickle', 'wb', ) as file:\n",
    "# # with open('/content/drive/MyDrive/Colab Notebooks/NLP_poems/data/voc20klen20_test_news.pickle', 'wb', ) as file:\n",
    "#     pickle.dump((gener_news_recon, gener_news_trans, gener_poem_recon, gener_poem_trans), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e97f6188",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T21:02:48.841751Z",
     "start_time": "2022-05-16T21:02:35.621558Z"
    }
   },
   "outputs": [],
   "source": [
    "PAD_ID = token_model.subword_to_id('<PAD>')\n",
    "BOS_ID = token_model.subword_to_id('<BOS>')\n",
    "EOS_ID = token_model.subword_to_id('<EOS>')\n",
    "\n",
    "gener_news_recon = token_model.decode(gener_news_recon, ignore_ids=[PAD_ID, BOS_ID, EOS_ID])\n",
    "gener_news_trans = token_model.decode(gener_news_trans, ignore_ids=[PAD_ID, BOS_ID, EOS_ID])\n",
    "gener_poem_recon = token_model.decode(gener_poem_recon, ignore_ids=[PAD_ID, BOS_ID, EOS_ID])\n",
    "gener_poem_trans = token_model.decode(gener_poem_trans, ignore_ids=[PAD_ID, BOS_ID, EOS_ID])\n",
    "\n",
    "orig_news_recon = token_model.decode(test_news, ignore_ids=[PAD_ID, BOS_ID, EOS_ID])\n",
    "orig_poem_recon = token_model.decode(test_poem, ignore_ids=[PAD_ID, BOS_ID, EOS_ID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ixdOx-jHWEu",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T21:02:53.363639Z",
     "start_time": "2022-05-16T21:02:53.359107Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1651063983795,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "5ixdOx-jHWEu",
    "outputId": "78bf4b3c-42cb-4f96-af54-ff9f71a6c75c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "теракт произошел в субботу в индийском городе пуна погибли как минимум восемь человек сообщает агентство рейтер . взрывное устройство сработало в популярной закусочной когда внутри находилось много туристов и иностранцев . теракт на западе\n",
      "теракт произошел в субботу в индийском городе пуна погибли как минимум восемь человек сообщает агентство рейтер . взрывное взрывное в в внойной побесочной когда внутри много много и власти . . на западе\n",
      "лишь знаешь в меня | индийском городе пуна | как минимум восемь человек там . | все взрывное глядя в поэтной закутелчной когда когда внутри много много и и . . боль боль\n",
      "\n",
      "истребитель су ввс россии пропал с экранов радаров в хабаровском крае сообщил риа новости источник в дальневосточном военном округе . истребитель су ввс рф пропал с экранов радаров в хабаровском крае истреб\n",
      "истребитель су ввс россии пропал с экранов радаров в хабаровском крае сообщил риа новости источник в дальневосточном военном округе . истребитель су ввс рф рф с экранов радаров в хабаровском крае истреб\n",
      "истребитель су ввс | пропал с экранов радаров | боясьляю | как там увижу мысличном военном округе твоя . | су ввс просто мы с экранов рада мнеров | зла полете зла\n",
      "\n",
      "гусу хиддинку будет непросто приспособиться к работе в качестве главного тренера сборной турции по футболу сказал по телефону риа новости главный тренер томи валерий непомнящий который с год работал в турецких клуба\n",
      "гусу ньюку будет непросто долларовиться к работе в качестве главного тренера сборной турции футболу сказал сказал по телефону риа новости главный тренер телефону представительмнящий который который с год в турецкихких клуба\n",
      "гусушкаку будет непросто войнаиться к . |бра господи тыжу я сказал сказал по телефону | а ты а просто ветермнящий то который с тобой тобой в твоюкихких клуба\n",
      "\n",
      "россия кардинально изменила политику в отношениях со странами латинской америки в сторону интенсификации заявил в пятницу посол рф на кубе михаил камынин . действительно в последнее время отношения россии со странами латинской америки меня\n",
      "россия кардинально изменила мон в отношениях со странами компаний бази в сторонульнофикации заявил в пятницу рф рф на кубе михаилниннин . . действительно в последнее время россии со странамичиков ка меня\n",
      "лишь так милый изменила | в дым со мной . | в сторону перемен ждать | я ты просто кубе мнекают так . . действительно | последнее время время | со мной тогда любя меня меня\n",
      "\n",
      "руководитель администрации президента рф сергей нарышкин призвал активизировать работу по противодействию попыткам фальсифицировать историю россии в преддверии празднования летия победы во второй мировой войне . в российской истории эта дата летие победы\n",
      "руководитель администрации президента рф сергей нарышкин призвал активизировать работу по итогамствию попыткам фальсифицировать историю россии россии преддверии летия летия победы победы второй мировой . . в российской истории на на победы победы\n",
      "любовь моя я | но |шкин нельзя | и нас по слова все самиткам | вот историю | скажи лишь очень победы победы мне кто скажи . . | ты истории эта мне взгляд победы победы\n",
      "\n",
      "госсекретарь сша хиллари клинтон в телефонном разговоре со своим российским коллегой сергеем лавровым призвала рф двигаться вперед в работе над новым договором по снв с тем чтобы он был подписан в течение следующих двух\n",
      "госсекретарь сша хиллари клинтон в телефонном разговоре со своим российским коллегой сергеем лавровым призвала рф индии вперед в работе над над договором по с тем чтобы он он был за в течение пяти двух\n",
      "белым горло знаешь разве | телефонном мойре со своим дай тыем лавчесть |вала крепче вперед вперед нею нею нею простолымлым с тем чтобы он он был был мир когда ты тобой двух\n",
      "\n",
      "количество жителей иркутска отравившихся водой взятой в крещение около храма михаила архангела в понедельник утром увеличилось до человек сообщает в понедельник пресс служба иркутской мэрии . по данным на января число заболевши\n",
      "количество жителей иркутска отравившихся водой взятой в крещение около храма михаила архангелала понедельник понедельник призовой до до сообщает в понедельник пресс служба мэрии мэрии . по данным на января число заболевши\n",
      "количество жителей сладска отравившихся водой взятой | крещение то храма михаила мирла | мы куда | там там в понедельник пресстелтел . . по . | сегодня мы жизни моейвши\n",
      "\n",
      "ростехрегулирование на этой неделе может принять новый гост который запретит называть ессентуками нарзаном и другими раскрученными брендами воду добытую не из одноименных месторождений пишет\n",
      "ростехрегулирование на этой неделе может принять новый гост который запретит похоронсссс дляками рузаном и и ждатьру цветов брендами воду душетуютую из изменных рейсов пишет\n",
      "ростехность была на этой тебя может принять новый го . | пить вот есс дляками нарзаном и смей ждатьру твоих брендами водуясьтую не из окнаменных тают пишет пишет\n",
      "\n",
      "всемирно известный канадский цирк дю солей планирует расширить свою деятельность в рф создав здесь постоянно действующее шоу с объемом инвестиций от миллионов долларов сообщил руководитель представительства цирка в россии крэг ко\n",
      "всемирно известный канадский цирк дем солей планирует расширить свою деятельность в рф создав здесь постоянно контроль посвящен шоу с с инвестиций от миллионов долларов сообщил руководитель организаторыского цирка россии к намг ко\n",
      "свет известный канад стук | тишина | солей . | свою деятельность в и созда здесь здесь ждать боясь боясь с любовью | от от . | просто мне ци ци | | нам нам пахнет ко ко\n",
      "\n",
      "многоцелевому транспортному модулю леонардо входящему в американский сегмент международной космической станции найдено новое применение он будет преобразован в постоянный многоцелевой модуль говорится в сообщении . ле\n",
      "много выступитвому транспортному площадейлю леонардо входящему в американский сообщаетсямент международной космической станции джистка ким будет будетн в постоянный многоцецеце университета представитель говорится в сообщении . ле\n",
      "много забытьвому смотрела | кольлю ле тутрдо |щему |юсь мы где космической станции слова | он будет этон | так многоцецеце тутдон . | . . ле ле\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20, 30):\n",
    "  print(orig_news_recon[i])\n",
    "  print(gener_news_recon[i])\n",
    "  print(gener_news_trans[i])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "r5RF3SUBJiEr",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T21:11:00.148170Z",
     "start_time": "2022-05-16T21:11:00.130117Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1651064042534,
     "user": {
      "displayName": "Вика",
      "userId": "07891139911062556455"
     },
     "user_tz": -180
    },
    "id": "r5RF3SUBJiEr",
    "outputId": "669a4b45-1e63-4701-de91-399ad15b596d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мама разрешила свете | взять из вазочки конфеты | и сказала обещай мне | столько взять чтоб угощая | никого не обойти . | всех конфеткой угости . | света\n",
      "мама разрешила свете | взять из вазочки конфеты | и сказала обещай мне столько столько взять чтоб угощая | никого не спокой . | всех конфеткой угости . | света\n",
      "мама разрешила корпорация | взять из вазочки конфеты среду и сказала обещайдара скончался столько взять чтоб одного угощая медведев призывает полтора сша . всех всехеткойции угости . света\n",
      "\n",
      "теперь не умирают от любви | насмешливая трезвая эпоха . | лишь падает гемоглобин в крови | лишь без причины человеку плохо . | с юлия друнина | добрый\n",
      "теперь не умирают от любви | насмешливая трезвая эпоха . | лишь падает гглогло | в крови | лишь без проблем плохо . | с с дру друнина | добрый\n",
      "теперь службы умирают от любви главный наставникшливая трезвая бригадыха стоимость сша лишь сша г лидерглобин в четверг в четверг без могут призывает власти . с с юлия нынешнийнина виктор добрый\n",
      "\n",
      "вот опять пришла зима | с елками и хороводом | скользким льдом | и новым годом | с тропкой лыжною в снегу | и снежинкой на лету . |\n",
      "вот опять пришла зима | с елками и хороводом | скользким льдом | и новым годом | с тропкой лыжною в снегу | и снежнымкой на на лету .\n",
      "министерство великобритании пришла зима | с елками и хороводом президентджи джейрскийстом и сша новым годом с троп эр четвер лыжно в в в четверг утром итогам полтора на на соревнования .\n",
      "\n",
      "снегом окутаны грустные морды кустарников . | скучно глотать в одиночку подтаявший мир . | каплями мутными сны мои вещие таяли | и по столу\n",
      "снегом окутаны грустные морды кустарников . | скучно глотать в одиночку подтаявший мир . | каплями мутными мои мои вещие неболи | и по столу\n",
      "снегом окутаны синаные морды кустарников . | скучно глотать в сшачку подтаявшийвший региональ мчс рф каплями мургиным вещие московском представитель представитель по по столу\n",
      "\n",
      "в твои лета еще летать | а не записывать в тетрадь | как в черный ящик | всю подноготную свою | пока живешь еще по сю | пока летящий . | а впрочем\n",
      "в твои лета еще летать | а не запи знать в тетрадь | как в черный ящик | всю подного свою свою | пока еще еще по по | пока летящий . | а впрочем\n",
      "в челябин лета еще летать | а не московская знать в рфдь | как в черный пятницу пятницущик намерен всю подного владимир свою пока пока еще еще по рф пока рф рф рф рф а впрочем\n",
      "\n",
      "очень жаль что мы не исключение | только исключительно для нас . | осень та моя пора весенняя | повела неслышно свой рассказ . | эта ночь отдав тепло не спорила | с\n",
      "очень жаль что мы не исключение | только исключительно для нас . | осень та моя пора весенняя | повела неслышно свой свой . | эта ночь отдав тепло не спорила | с\n",
      "очень жаль что франции не исключение главный метео выборах для нас стоимость медведев управление та посвящен посвящен пора ракетыняя медведев повела власти получили свой стоимость . стоимость вторую ночьв тепло не спогло рф с\n",
      "\n",
      "как много девушек пригожих . | как горячи и сладки сны | когда твой образ их тревожит | в ожидании весны | надежд полны . | ах миша | с тобой не хочется покоя .\n",
      "как много девушек приго образова . | как горячи и сладки сны | когда твой образ их тревожит | в ожидании весны надежд надежд . | | ах миша | тобой тобой не хочется покоя .\n",
      "признание много путин приго образованово главный словам горячи среду сла района новгородской области когда российский образ образ их зимних в в четверг пострадавших установить надежд открытого четверг воскресенье миша премьер с тобой не могут граждане .\n",
      "\n",
      "заметь меня в толпе под универом | с улыбкой милой на лице | я буду в платье ярко сером | стучать туфлями на крыльце | и ждать тебя плевать что холод\n",
      "заметь меня в толпе под универом | с улыбкой милой на лице | я буду в платье ярко сером | сту стучатьффлями нацеце | ждать ждать плевать что холод\n",
      "за партии лидер в суде под универом востоке с улыбкой путин на лице на пятницу пятницу президенты в платье ярко серомром стучать туфлями на на среду рф и намерен намерен намерен холод\n",
      "\n",
      "посмотри мне в глаза | там застыла слеза | моих чувств небеса | догорают . | там рассвет и закат | злых часов циферблат | тех что время для нас | отмеряют\n",
      "посмотри мне в глаза | там застыла слеза | моих чувств небеса | догорают . | там рассвет и закат | злых часов циферблат | тех что время для нас | отмерре\n",
      "посмотри мне в глаза | там финансовой слезального моих чувств небеса | догораютют . там там рассвет и небольшой | злых часов циферблатщение тех время для для место отмервшийся\n",
      "\n",
      "не оттолкну а выпью чашу с ядом | коль этот яд нальет твоя рука | сочту за честь и высшую награду | взгляд брошенный тобою свысока | подставлю\n",
      "не оттолкну а выпью чашу с ядом | коль этот яд нальет твоя рука | нату за честь и высшую награду | взгляд брошенный смычкомсока | подставлю\n",
      "не министрал эр аческойью чашу ссерджи коль футболу энди энди медвед медведцева владимир на сша за за честь сша высшую награду состав рф брошенный представительсокака соревнованиялю\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(30, 40):\n",
    "  print(orig_poem_recon[i])\n",
    "  print(gener_poem_recon[i])\n",
    "  print(gener_poem_trans[i])\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ST_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "149424d11ffc42c7bdcf0aca4d0a4b2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c3379e2c91543ceb9476aa2fbb47669": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "65502f417cd44677b5b7e3f3f095dee4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96726c6387c8421582ca95dbbf1725a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c0a80eed03654f4286a8253856e9dc23",
       "IPY_MODEL_f5889def24a54bae8cf98e4417158359",
       "IPY_MODEL_efbb9250cc044a00bae22fa663fb63f7"
      ],
      "layout": "IPY_MODEL_fe518ed238524213a751a4ebb61e4169"
     }
    },
    "a0c45bb7820c44aebb5f73da32bf2188": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0a80eed03654f4286a8253856e9dc23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d912a8318c064df0a070fa1bacf30e0c",
      "placeholder": "​",
      "style": "IPY_MODEL_1c3379e2c91543ceb9476aa2fbb47669",
      "value": "100%"
     }
    },
    "ca66c185131c46c3abbe16180b525717": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d912a8318c064df0a070fa1bacf30e0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efbb9250cc044a00bae22fa663fb63f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0c45bb7820c44aebb5f73da32bf2188",
      "placeholder": "​",
      "style": "IPY_MODEL_65502f417cd44677b5b7e3f3f095dee4",
      "value": " 24/24 [01:57&lt;00:00,  4.29s/it]"
     }
    },
    "f5889def24a54bae8cf98e4417158359": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca66c185131c46c3abbe16180b525717",
      "max": 24,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_149424d11ffc42c7bdcf0aca4d0a4b2f",
      "value": 24
     }
    },
    "fe518ed238524213a751a4ebb61e4169": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
