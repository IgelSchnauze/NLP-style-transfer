{"cells":[{"cell_type":"code","execution_count":null,"id":"e8vkfZSUsZ9b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18307,"status":"ok","timestamp":1649335975438,"user":{"displayName":"Вика","userId":"07891139911062556455"},"user_tz":-180},"id":"e8vkfZSUsZ9b","outputId":"82a2764a-214a-40f9-867a-aa9d48209483"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"id":"gzBhWOnUDOXL","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4503,"status":"ok","timestamp":1649335979936,"user":{"displayName":"Вика","userId":"07891139911062556455"},"user_tz":-180},"id":"gzBhWOnUDOXL","outputId":"fb085a72-02bb-4a31-8d55-b70cac1efaee","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting youtokentome\n","  Downloading youtokentome-1.0.6-cp37-cp37m-manylinux2010_x86_64.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from youtokentome) (7.1.2)\n","Installing collected packages: youtokentome\n","Successfully installed youtokentome-1.0.6\n"]}],"source":["!pip install youtokentome"]},{"cell_type":"code","execution_count":null,"id":"ab9ca873","metadata":{"id":"ab9ca873"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","\n","import youtokentome as yttm\n","import numpy as np\n","\n","import random\n","import math\n","import time\n","import pickle\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":null,"id":"b6018908","metadata":{"id":"b6018908"},"outputs":[],"source":["SEED = 1234\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":null,"id":"f92d980d","metadata":{"id":"f92d980d"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# device = torch.device('cpu')"]},{"cell_type":"code","execution_count":null,"id":"3089450a","metadata":{"id":"3089450a"},"outputs":[],"source":["# token_model = yttm.BPE(model='try_poems_embed_yttm.model', n_threads=-1)\n","token_model = yttm.BPE(model='/content/drive/MyDrive/Colab Notebooks/NLP_poems/voc10k_poems_embed_yttm.model', n_threads=-1)"]},{"cell_type":"code","execution_count":null,"id":"ca3d5413","metadata":{"id":"ca3d5413"},"outputs":[],"source":["class newDataset(Dataset):\n","    def __init__(self, data_list_of_list):\n","        self.data = data_list_of_list\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        return self.data[index]\n","\n","    def cut_length(self):\n","#         middle_len = sum([len(text) for text in self.data])/len(self.data)\n","#         limit = int(middle_len)*2\n","        limit = 10\n","        self.data = [text if len(text)<limit else text[:limit] for text in self.data]\n","\n","    def distribute_data(self, share_tr, share_val):  # examle = (0.8, 0.1)\n","        rand_i = np.random.permutation(len(self.data))\n","        n1 = int(len(self.data) * share_tr)\n","        n2 = int(len(self.data) * share_val)\n","        # return self.data[rand_i[0: n1]], self.data[rand_i[n1: n1 + n2]], self.data[rand_i[n1 + n2:]]\n","        return [self.data[i] for i in rand_i[0: n1]], \\\n","               [self.data[i] for i in rand_i[n1: n1 + n2]], \\\n","               [self.data[i] for i in rand_i[n1 + n2:]]\n","    \n","def padding(batch):\n","    pad_id = token_model.subword_to_id('<PAD>')\n","    \n","    batch = [torch.tensor(x) for x in batch]\n","    batch = pad_sequence(batch, batch_first=False, padding_value=pad_id)  # batch_first=True -> [batch size, len]\n","    return batch\n","    # return batch.to(device)"]},{"cell_type":"code","execution_count":null,"id":"04f0c0b2","metadata":{"id":"04f0c0b2"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        \n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        \n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        \n","        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers) # dropout = dropout\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src):      \n","        #src = [src len, batch size]\n","        \n","        embedded = self.dropout(self.embedding(src))\n","        #embedded = [src len, batch size, emb dim]\n","        \n","        outputs, hidden = self.rnn(embedded)\n","        #outputs = [src len, batch size, hid dim * n directions]\n","        #hidden = [n layers * n directions, batch size, hid dim]\n","        \n","        return hidden"]},{"cell_type":"code","execution_count":null,"id":"e524e3a2","metadata":{"id":"e524e3a2"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        \n","        self.output_dim = output_dim  # the size of the vocabulary for the output/target.\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        \n","        self.embedding = nn.Embedding(output_dim, emb_dim) # 1 - size of dict emb, 2 - size of emb vec\n","        \n","        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers) # dropout = dropout\n","        \n","        self.fc_out = nn.Linear(hid_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden):\n","        #n directions in the decoder will both always be 1, therefore:\n","        #hidden = [n layers, batch size, hid dim]\n","        \n","        #input = [batch size]\n","        input = input.unsqueeze(0) \n","        #input = [1, batch size]\n","        \n","        embedded = self.dropout(self.embedding(input))\n","        #embedded = [1, batch size, emb dim]\n","                \n","        output, hidden = self.rnn(embedded, hidden)\n","        #output = [1, batch size, hid dim], seq len will always be 1 in the decoder\n","        #hidden = [n layers, batch size, hid dim]\n","        \n","        prediction = self.fc_out(output.squeeze(0))\n","        #prediction = [batch size, output dim]\n","        \n","        return prediction, hidden"]},{"cell_type":"code","execution_count":null,"id":"c49c37e0","metadata":{"id":"c49c37e0"},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","    def forward(self, src, trg, teacher_forcing_ratio = 0.2):\n","        \n","        #src = [src len, batch size]\n","        #trg = [trg len, batch size]\n","        #teacher_forcing_ratio=0.75 -> use ground-truth inputs 75% of the time\n","        \n","        batch_size = trg.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","        \n","        #last hidden state of the encoder = the initial hidden state of the decoder\n","        hidden = self.encoder(src)\n","        \n","        #first input to the decoder is the <bos> tokens\n","        input = trg[0,:]\n","        \n","        for t in range(1, trg_len):\n","            \n","            #insert input token embedding, previous hidden states\n","            #receive output tensor (predictions) and new hidden states\n","            output, hidden = self.decoder(input, hidden)\n","            \n","            outputs[t] = output\n","            \n","            teacher_force = random.random() < teacher_forcing_ratio\n","            \n","            #get the highest predicted token\n","            top1 = output.argmax(1) \n","            \n","            #if teacher forcing, use actual next token, else use predicted token\n","            input = trg[t] if teacher_force else top1\n","        \n","        return outputs"]},{"cell_type":"code","execution_count":null,"id":"6c03553f","metadata":{"id":"6c03553f"},"outputs":[],"source":["INPUT_DIM = token_model.vocab_size() \n","OUTPUT_DIM = INPUT_DIM\n","ENC_EMB_DIM = 128 #256\n","DEC_EMB_DIM = 128 #256\n","HID_DIM = 256 #512\n","N_LAYERS = 2\n","ENC_DROPOUT = 0.2 \n","DEC_DROPOUT = 0.2\n","\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n","\n","model = Seq2Seq(enc, dec, device).to(device)"]},{"cell_type":"code","execution_count":null,"id":"a28baf9d","metadata":{"id":"a28baf9d"},"outputs":[],"source":["PAD_ID = token_model.subword_to_id('<PAD>')\n","criterion = nn.CrossEntropyLoss(ignore_index = PAD_ID)"]},{"cell_type":"code","execution_count":null,"id":"IJQffBFbO4kw","metadata":{"id":"IJQffBFbO4kw"},"outputs":[],"source":["def test(model, loader, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    outputs_list = []\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(tqdm(loader)):\n","            batch = batch.to(device, non_blocking=True)\n","            src = batch\n","            trg = batch\n","\n","            output = model(src, trg, 0) #turn off teacher forcing\n","            outputs_list.append(torch.transpose(output, 0, 1))\n","\n","            #trg = [trg len, batch size]\n","            #output = [trg len, batch size, output dim]\n","\n","            output_dim = output.shape[-1]\n","\n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            #trg = [(trg len - 1) * batch size]\n","            #output = [(trg len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, trg)\n","            \n","            epoch_loss += loss.item()\n","      \n","    return epoch_loss / len(loader), outputs_list"]},{"cell_type":"code","source":["# optimizer.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/NLP_poems/b7e10dr03_optim.pt'))\n","# print(optimizer.param_groups[0]['lr'])\n","# print(optimizer.param_groups[0]['initial_lr'])\n","# print(optimizer.param_groups)"],"metadata":{"id":"NdaSGo5KZgDN"},"id":"NdaSGo5KZgDN","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"4v_oHkIGWHGB","metadata":{"id":"4v_oHkIGWHGB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649248270032,"user_tz":-180,"elapsed":2170,"user":{"displayName":"Вика","userId":"07891139911062556455"}},"outputId":"3a39b297-7d1c-4fac-b1ee-c6a4ddca57a7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":15}],"source":["# checkpoint = torch.load('trylr005_17k_checkpoint.pt')\n","checkpoint = torch.load('/content/drive/MyDrive/Colab Notebooks/NLP_poems/AdamW01_C005_drEm2_voc10k_tf2_len10_Att_checkp_last.pt', \n","                        map_location=torch.device('cpu'))\n","model.load_state_dict(checkpoint['model_state_dict'])"]},{"cell_type":"code","execution_count":null,"id":"6d0b297f","metadata":{"id":"6d0b297f"},"outputs":[],"source":["# with open('data/try_test_data_token.pickle', 'rb', ) as file:\n","with open('/content/drive/MyDrive/Colab Notebooks/NLP_poems/data/voc10klen20_test_data_token.pickle', 'rb', ) as file:\n","    test_data_token = pickle.load(file)\n","test_loader_load = DataLoader(\n","    test_data_token, batch_size=128, shuffle=False, num_workers=1, pin_memory=True, collate_fn=padding)"]},{"cell_type":"code","execution_count":null,"id":"6c4fe1ca","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["5a9614332401433c95d492eb057ad7ea","171ce502047a4cb6ba916d51ed1c6465","2e7c86e4d000485bb1f3833ee5c05312","9d7929819c9941c7b979ee5b8964d4cf","49af4b7e75874d7cae39bdb96f70b007","34112eb0344e46fdadb6c19a5a4bbcec","ea86bc1183d34dd19724be19e3080fb9","029c8b23c81a4592b3bf7c8a60ff191d","02591d162528470d8cac71777629a47b","5dc0438f17b54b59879cd478f074a3cb","6888ccf2e58d43b990c31bdcdfe09d87"]},"executionInfo":{"elapsed":12108,"status":"ok","timestamp":1649248285603,"user":{"displayName":"Вика","userId":"07891139911062556455"},"user_tz":-180},"id":"6c4fe1ca","outputId":"df63b95f-6fe3-47a3-8a29-383f1b49d48d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/14 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a9614332401433c95d492eb057ad7ea"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["| Test Loss: 4.170 | Test PPL:  64.719 |\n"]}],"source":["test_loss, test_poems_embed = test(model, test_loader_load, criterion)\n","\n","print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"]},{"cell_type":"markdown","id":"8d1bf83a","metadata":{"id":"8d1bf83a"},"source":["#### Get poems from test output and compare with orig test poems"]},{"cell_type":"code","execution_count":null,"id":"4-wN6RFOSyMB","metadata":{"id":"4-wN6RFOSyMB"},"outputs":[],"source":["generated_poems_token = []\n","generated_poems_len = []\n","PAD_ID = token_model.subword_to_id('<PAD>')\n","BOS_ID = token_model.subword_to_id('<BOS>')\n","EOS_ID = token_model.subword_to_id('<EOS>')\n","for batch in test_poems_embed:\n","    for text_word_probab in batch:\n","        text_vocab_ids = [torch.argmax(word).item() for word in text_word_probab]\n","        generated_poems_token.append(text_vocab_ids)\n","        generated_poems_len.append(len(text_vocab_ids))\n","\n","generated_poems = token_model.decode(generated_poems_token, ignore_ids=[PAD_ID]) \n","\n","orig_poems = token_model.decode(test_data_token, ignore_ids=[PAD_ID, BOS_ID, EOS_ID]) "]},{"cell_type":"code","execution_count":null,"id":"2749fe1c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":301,"status":"ok","timestamp":1649248295473,"user":{"displayName":"Вика","userId":"07891139911062556455"},"user_tz":-180},"id":"2749fe1c","outputId":"e9885dab-2141-4e74-f4f6-d22f56c5849b"},"outputs":[{"output_type":"stream","name":"stdout","text":["если надо уносижать не наруслав полй . не не не не не не не не\n","если надо уезжать не толпитесь стадом . политтройка не спеша всех\n","\n","над самой бездной на крыль уздой железной избу огне и и и и и и и и и\n","над самой бездной на высоте уздой железной россию поднял на дыбы пушкин город змеи и медного\n","\n","на губках смех в сердечке благодать которую печальный в страным иною и иною и\n","на губках смех в сердечке благодать которую ни светских правил стужа ни мненья\n","\n","только русский знавший с детства тристь уст природа от предмия пред предмими с\n","только русский знавший с детства тяжесть вечной духоты с жизнью ваявший как наслед\n","\n","я инок темный нищ и гол . я я я я я я я я я\n","я инок темный нищ и гол мне был глагол как гром огромный когда качая\n","\n","упала лепетса и снова сурово разъяты закаром в в в и и и и в и\n","упала завеса и снова сурово разъяты закаты в горбатые старые скаты и в\n","\n","посв . а курсинскому летит и и на на на на на на на на\n","посв . а курсинскому летит земля на крыльях духа тьмы летит навстречу солнцу и\n","\n","будешь помнить прогремела мне томишка посистью . . . . . . . . .\n","будешь помнить прогремела мне насмешка посидона . коней бурных он направил в глубь\n","\n","он был в краювятом на холмах . по по по по . . по по .\n","он был в краю святом на холмах палестины . стальной его шелом ис\n","\n","я еду . на небе высоко плывет уж крайшел и и и и и и и и и\n","я еду . на небе высоко плывет уж бледная луна и от селенья недалеко дорога старая\n","\n","да я любила их те сборищажий . . . . . . . . . .\n","да я любила их те сборища ночные на маленьком столе стаканы ледяные над черным\n","\n","любим калифом иоанн ему что день и и и и и и и и и и\n","любим калифом иоанн ему что день почет и ласка к делам правления призван\n","\n","кто неутоленный ищет просит встречи . о как хорош в . . . . . . . .\n","кто неутоленный ищет просит встречи . о как хорош мой вечер безымянный бездонный вечер .\n","\n","аминь глаголю вам в восторге пыли стити в на на на на на на на\n","аминь глаголю вам в восторге рек марк вич когда к москве реке задумчив\n","\n","герои рабочий стали орлы из рабов . отчего . вы . . . . . . . .\n","герои рабочий стали орлы из рабов . отчего . спроси рабочего . красноармеец если красное знамя\n","\n","мальчик солнце сейчас должно с торжеством в концев и и и и и и и и и\n","мальчик солнце встретить должно с торжеством в конце пиров . принеси же осторожно и скорей из\n","\n","нет мира для меня хотя и дышать нет в в в в в в в в в в в\n","нет мира для меня хотя и брани нет в надежде в страхе я в груди то хлад то пламень\n","\n","и вот там просренной морских журчадим тарю . . . . . . . . .\n","и вот там сидят женщины плачущие по тамузе . иезекииль идите\n","\n","ступени стро зимою околдованни где в нальль и на на на на\n","чародейкою зимою околдован лес стоит и под снежной бахромою неподвижною\n","\n","ты печально мерцала между ярких алмаз и одна то твои .ла . . . . . .\n","ты печально мерцала между ярких подруг и одна не вступала в их пленительный круг . незамет\n","\n","с латинского скорее челюстью два на . . . . . . . в в\n","с латинского скорее челюстью своей поднимет солнце муравей скорей вода с огнем\n","\n","все были свиданьяны давно заветы сладостной твой их и и и и и и и и\n","все были сказаны давно заветы сладостной свободы и прежде претворялись воды в животворя\n","\n","не ветры птиют пущи не листонвой и и и и и и и и\n","не ветры осыпают пущи не листопад златит холмы . с голубизны незри\n","\n","на столике чай пеняют с мраморныеке в ики и и и и и и\n","на столике чай печения сдобные в серебряной вазочке драже . подо\n","\n","граждане мне начинает казаться что вы петустой коль . . .туту . .ту\n","граждане мне начинает казаться что вы недостойны индустриализации . граждане дя\n","\n","тот город мной любимый с детства в егоствии подногоного солненых . . . . .\n","тот город мной любимый с детства в его декабрьской тишине моим промотанным наследством\n","\n","мое прикосновенье мой согласно поцелуй как притно . . . . . . . .\n","мое прикосновенье мой сладкий поцелуй как светлое забвенье как пенье вешних струй . воздуш\n","\n","а сколько радости и неги в бегущих луч на вке .не .не .не .\n","а сколько радости и неги в бегущих медленно часах . следов доискиваться в\n","\n","на спичечной коробке смотри кады . . . . не не . . не\n","на спичечной коробке смотри ка славный вид кораблик трехмачтовый не двига\n","\n","на заре ты ее нелег на заре она облака на на на на на на на на на\n","на заре ты ее не буди на заре она сладко так спит утро дышит у ней на груди ярко\n","\n"]}],"source":["for id in range(0, 30):\n","  # print(generated_poems_len[id])\n","  # print(len(orig_poems[id].split(' ')))\n","  print(generated_poems[id])\n","  print(orig_poems[id])\n","  print()"]},{"cell_type":"markdown","source":["#### Use metric to evaluate results"],"metadata":{"id":"1k5NOj3aaY6o"},"id":"1k5NOj3aaY6o"},{"cell_type":"code","source":["embedding = nn.Embedding(OUTPUT_DIM, DEC_EMB_DIM) # 1 - size of dict emb, 2 - size of emb vec\n","\n","embed_source_poems = embedding(torch.tensor(generated_poems_token)) # [poems num, word num, embed len]\n","embed_target_poems = embedding(torch.tensor(test_data_token))"],"metadata":{"id":"ZngSy1C3Epcz","colab":{"base_uri":"https://localhost:8080/","height":200},"executionInfo":{"status":"error","timestamp":1649248384945,"user_tz":-180,"elapsed":5512,"user":{"displayName":"Вика","userId":"07891139911062556455"}},"outputId":"0d3f07f8-38c0-4a10-bb06-84d032631bf1"},"id":"ZngSy1C3Epcz","execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-a5055b0d59b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membed_source_poems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_poems_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [poems num, word num, embed len]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0membed_target_poems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: expected sequence of length 20 at dim 1 (got 17)"]}]},{"cell_type":"code","source":["total_score = 0\n","for i in range(len(embed_target_poems)):\n","    embed_source_poem = embed_source_poems[i]  # [word num, embed len]\n","    embed_target_poem = embed_target_poems[i]\n","    # print(embed_source_poem.shape , embed_target_poem.shape)\n","    # print(embed_source_poem, embed_target_poem)\n","\n","    # [min, mean, max] = sentence emb-g\n","    v_s_min = torch.min(embed_source_poem)\n","    v_s_mean = torch.mean(embed_source_poem)\n","    v_s_max = torch.max(embed_source_poem)\n","\n","    v_t_min = torch.min(embed_target_poem)\n","    v_t_mean = torch.mean(embed_target_poem)\n","    v_t_max = torch.max(embed_target_poem)\n","\n","    v_s = torch.tensor([v_s_min, v_s_mean, v_s_max])\n","    v_t = torch.tensor([v_t_min, v_t_mean, v_t_max])\n","    # print(v_s, v_t)\n","\n","    score = torch.matmul(v_s.t(), v_t) / (torch.linalg.norm(v_s, ord=2) * torch.linalg.norm(v_t, ord=2))\n","    # if source = orig, then score = 1.0, else score < 1.0\n","    total_score += (1.0 - score)\n","    \n","total_score = total_score.item()\n","print(total_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9odfD-mra5P8","executionInfo":{"status":"ok","timestamp":1649086537720,"user_tz":-180,"elapsed":439,"user":{"displayName":"Вика","userId":"07891139911062556455"}},"outputId":"4081e87f-f6d4-44d7-a7d4-51d82e5eecda"},"id":"9odfD-mra5P8","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2617645263671875\n"]}]},{"cell_type":"code","source":["# print(token_model.vocab()[:30])\n","token_model.subword_to_id(' \\n')\n","token_model.encode('где бы ты не был \\n в каких бы краях . \\n я бы всегда ')\n","token_model.encode('где бы ты не был \\n в каких бы краях . \\n я бы всегда ', output_type=yttm.OutputType.SUBWORD)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7kz6aQNrDxdv","executionInfo":{"status":"ok","timestamp":1648547474209,"user_tz":-180,"elapsed":267,"user":{"displayName":"Вика","userId":"07891139911062556455"}},"outputId":"9fd20154-a012-4a29-877f-1b97abe19ef7"},"id":"7kz6aQNrDxdv","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['▁где',\n"," '▁бы',\n"," '▁ты',\n"," '▁не',\n"," '▁был',\n"," '▁в',\n"," '▁каких',\n"," '▁бы',\n"," '▁краях',\n"," '▁.',\n"," '▁я',\n"," '▁бы',\n"," '▁всегда']"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["a = torch.tensor(\n","    [\n","     [[1,2],[3,4],[5,6],[7,8]],\n","     [[0,0],[1,1],[2,2],[3,3]],\n","     [[-1,-1],[-2,-2],[-3,-3],[-4,-4]]\n","    ]\n",")\n","print(a.shape) # [3, 4, 2]\n","# в каждом стихе 3 слова, всего 4 стиха, каждое слово из 2х букв\n","\n","a = torch.transpose(a, 0, 1)\n","print(a.shape) # [4, 3, 2]\n","print(a)"],"metadata":{"id":"xwXL2dBNZYK0"},"id":"xwXL2dBNZYK0","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"test_gru.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"5a9614332401433c95d492eb057ad7ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_171ce502047a4cb6ba916d51ed1c6465","IPY_MODEL_2e7c86e4d000485bb1f3833ee5c05312","IPY_MODEL_9d7929819c9941c7b979ee5b8964d4cf"],"layout":"IPY_MODEL_49af4b7e75874d7cae39bdb96f70b007"}},"171ce502047a4cb6ba916d51ed1c6465":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_34112eb0344e46fdadb6c19a5a4bbcec","placeholder":"​","style":"IPY_MODEL_ea86bc1183d34dd19724be19e3080fb9","value":"100%"}},"2e7c86e4d000485bb1f3833ee5c05312":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_029c8b23c81a4592b3bf7c8a60ff191d","max":14,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02591d162528470d8cac71777629a47b","value":14}},"9d7929819c9941c7b979ee5b8964d4cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5dc0438f17b54b59879cd478f074a3cb","placeholder":"​","style":"IPY_MODEL_6888ccf2e58d43b990c31bdcdfe09d87","value":" 14/14 [00:11&lt;00:00,  1.77it/s]"}},"49af4b7e75874d7cae39bdb96f70b007":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34112eb0344e46fdadb6c19a5a4bbcec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea86bc1183d34dd19724be19e3080fb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"029c8b23c81a4592b3bf7c8a60ff191d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02591d162528470d8cac71777629a47b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5dc0438f17b54b59879cd478f074a3cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6888ccf2e58d43b990c31bdcdfe09d87":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}